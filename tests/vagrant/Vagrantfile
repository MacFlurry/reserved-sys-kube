# Vagrantfile ‚Äî Kubernetes (kubeadm + containerd + Calico) sur Ubuntu 24.04 ARM64
# Provider: VMware Fusion (vagrant-vmware-desktop)
# 1 control-plane (3 vCPU / 4GB) + 1 worker (2 vCPU / 2GB) ‚Äî Pod CIDR Calico: 192.168.0.0/16
# Version am√©lior√©e avec meilleures pratiques de s√©curit√© et fiabilit√©

VAGRANT_DEFAULT_PROVIDER = "vmware_desktop"

# ========== CONFIGURATION GLOBALE ==========
BOX_NAME            = "bytesguy/ubuntu-server-24.04-arm64"
K8S_VERSION         = "v1.32"           # Version mineure pour le d√©p√¥t apt
K8S_PACKAGE_VERSION = "1.32.0-1.1"      # Version exacte des packages (reproductibilit√©)
CALICO_VERSION      = "v3.30.4"         # Version Calico (compatibilit√© v√©rifi√©e avec K8s 1.32)
POD_CIDR            = "192.168.0.0/16"  # CIDR des pods (doit correspondre √† Calico)
CLUSTER_NAME        = "k8s-lab"
IP_BASE             = "192.168.56"
REPO_ROOT           = File.expand_path("../..", __dir__) # Racine du repo (parent de tests/)

# ========== TOPOLOGIE DU CLUSTER ==========
NODES = [
  { name: "cp1", ip_octet: 10, role: "control-plane", cpus: 3, memory: 4096 },
  { name: "w1",  ip_octet: 11, role: "worker",        cpus: 2, memory: 2048 },
]

# Validation de la topologie
CONTROL_PLANE    = NODES.find { |n| n[:role] == "control-plane" }
CONTROL_PLANE_IP = "#{IP_BASE}.#{CONTROL_PLANE[:ip_octet]}" if CONTROL_PLANE
raise "ERREUR: NODES doit contenir au moins un n≈ìud control-plane" unless CONTROL_PLANE_IP

# ========== SCRIPT DE PROVISIONING COMMUN ==========
COMMON_PROVISION = <<-SHELL
  set -euxo pipefail

  # Marqueur d'idempotence pour √©viter les re-provisions inutiles
  PROVISION_MARKER="/etc/kubernetes/.common-provisioned"
  if [ -f "$PROVISION_MARKER" ]; then
    echo "‚è≠Ô∏è  Provisioning commun d√©j√† effectu√© (marqueur trouv√©)"
    exit 0
  fi

  echo "üîÑ Attente de cloud-init (√©vite les courses avec SSH/r√©seau)..."
  command -v cloud-init >/dev/null 2>&1 && cloud-init status --wait || true

  # ========== 1) PR√â-REQUIS NOYAU + SYSCTL ==========
  echo "üì¶ Configuration des modules kernel requis..."
  cat >/etc/modules-load.d/k8s.conf <<'EOF'
overlay
br_netfilter
EOF
  modprobe overlay || true
  modprobe br_netfilter || true

  cat >/etc/sysctl.d/99-kubernetes-cri.conf <<'EOF'
net.bridge.bridge-nf-call-iptables = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward = 1
EOF
  sysctl --system

  # ========== 2) D√âSACTIVER LA SWAP ==========
  echo "üíæ D√©sactivation de la swap (requis pour Kubernetes)..."
  swapoff -a || true
  sed -ri '/\\sswap\\s/s/^/#/' /etc/fstab || true

  # ========== 3) INSTALLATION ET CONFIGURATION DE CONTAINERD ==========
  echo "üê≥ Installation de containerd avec SystemdCgroup..."
  apt-get update
  apt-get install -y --no-install-recommends \\
    containerd \\
    ca-certificates \\
    curl \\
    gpg \\
    apt-transport-https

  mkdir -p /etc/containerd
  if [ ! -s /etc/containerd/config.toml ]; then
    containerd config default | tee /etc/containerd/config.toml >/dev/null
  fi

  # Configuration SystemdCgroup = true (recommandation officielle)
  sed -ri 's/^\\s*SystemdCgroup = .*/            SystemdCgroup = true/' /etc/containerd/config.toml

  systemctl daemon-reload
  systemctl enable containerd
  systemctl restart containerd

  # Attente stabilit√© de containerd (critique sur ARM64)
  echo "‚è≥ Attente de la stabilisation de containerd (15s)..."
  sleep 15

  # V√©rification que containerd est actif
  if ! systemctl is-active --quiet containerd; then
    echo "‚ùå ERREUR: containerd n'a pas d√©marr√© correctement"
    systemctl status containerd
    exit 1
  fi

  # ========== 4) D√âP√îT KUBERNETES + PACKAGES ==========
  echo "üîë Configuration du d√©p√¥t Kubernetes avec v√©rification GPG..."
  install -m 0755 -d /etc/apt/keyrings

  # T√©l√©chargement et installation de la cl√© GPG
  # Note: En production, v√©rifier l'empreinte GPG manuellement
  # gpg --show-keys /etc/apt/keyrings/kubernetes-apt-keyring.gpg
  if [ ! -f /etc/apt/keyrings/kubernetes-apt-keyring.gpg ]; then
    curl -fsSL https://pkgs.k8s.io/core:/stable:/#{K8S_VERSION}/deb/Release.key \\
      | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg
    chmod a+r /etc/apt/keyrings/kubernetes-apt-keyring.gpg
  fi

  cat >/etc/apt/sources.list.d/kubernetes.list <<EOF
deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/#{K8S_VERSION}/deb/ /
EOF

  # Installation des versions EXACTES (reproductibilit√©)
  echo "üì• Installation de kubelet, kubeadm, kubectl (version #{K8S_PACKAGE_VERSION})..."
  apt-get update
  apt-get install -y \\
    kubelet=#{K8S_PACKAGE_VERSION} \\
    kubeadm=#{K8S_PACKAGE_VERSION} \\
    kubectl=#{K8S_PACKAGE_VERSION}
  
  apt-mark hold kubelet kubeadm kubectl

  # Le kubelet est activ√© par d√©faut mais ne d√©marrera qu'apr√®s kubeadm init/join
  systemctl enable kubelet

  # Marquer le provisioning comme termin√©
  mkdir -p /etc/kubernetes
  touch "$PROVISION_MARKER"
  echo "‚úÖ Provisioning commun termin√© avec succ√®s"
SHELL

# ========== SCRIPT DE PROVISIONING CONTROL-PLANE ==========
MASTER_PROVISION = <<-SHELL
  set -euxo pipefail

  # Marqueur d'idempotence
  PROVISION_MARKER="/etc/kubernetes/.master-provisioned"
  if [ -f "$PROVISION_MARKER" ]; then
    echo "‚è≠Ô∏è  Provisioning control-plane d√©j√† effectu√©"
    exit 0
  fi

  echo "üéõÔ∏è  Initialisation du control plane..."

  # V√©rification que containerd est stable
  systemctl is-active --quiet containerd || systemctl restart containerd
  sleep 10

  # Arr√™t propre du kubelet avant kubeadm init (kubeadm le red√©marrera)
  systemctl stop kubelet 2>/dev/null || true

  # ========== INITIALISATION DU CLUSTER ==========
  if [ ! -f /etc/kubernetes/admin.conf ]; then
    echo "üöÄ Ex√©cution de kubeadm init..."
    kubeadm init \\
      --pod-network-cidr=#{POD_CIDR} \\
      --apiserver-advertise-address=#{CONTROL_PLANE_IP} \\
      --control-plane-endpoint=#{CONTROL_PLANE_IP} \\
      --upload-certs \\
      --v=5  # Verbosit√© pour d√©boguer si probl√®me
  else
    echo "‚úÖ Cluster d√©j√† initialis√© (admin.conf existe)"
  fi

  # ========== CONFIGURATION KUBECONFIG POUR VAGRANT ==========
  echo "üìù Configuration kubeconfig pour l'utilisateur vagrant..."
  mkdir -p /home/vagrant/.kube
  cp -f /etc/kubernetes/admin.conf /home/vagrant/.kube/config
  chown -R vagrant:vagrant /home/vagrant/.kube

  # ========== ATTENTE DE L'API SERVER ==========
  echo "‚è≥ V√©rification de la disponibilit√© de l'API server (timeout: 10 min)..."
  API_READY=false
  for i in $(seq 1 120); do
    if kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes >/dev/null 2>&1; then
      echo "‚úÖ API server pr√™t apr√®s $i tentative(s) ($(($i * 5))s)"
      API_READY=true
      break
    fi
    echo "‚è≥ Attente de l'API server... ($i/120 - $(($i * 5))s)"
    sleep 5
  done

  if [ "$API_READY" = false ]; then
    echo "‚ùå ERREUR CRITIQUE: L'API server ne r√©pond pas apr√®s 10 minutes"
    echo "üîç Logs kubelet:"
    journalctl -u kubelet -n 50 --no-pager
    echo "üîç Logs containerd:"
    journalctl -u containerd -n 50 --no-pager
    exit 1
  fi

  # ========== INSTALLATION DE CALICO CNI ==========
  if ! kubectl --kubeconfig=/etc/kubernetes/admin.conf get ns calico-system >/dev/null 2>&1; then
    echo "üåê Installation de Calico CNI (version #{CALICO_VERSION})..."
    curl -fsSL https://raw.githubusercontent.com/projectcalico/calico/#{CALICO_VERSION}/manifests/calico.yaml \\
      -o /tmp/calico.yaml
    kubectl --kubeconfig=/etc/kubernetes/admin.conf apply -f /tmp/calico.yaml

    # Attente que Calico soit pr√™t
    echo "‚è≥ Attente que Calico soit op√©rationnel (timeout: 10 min)..."
    kubectl --kubeconfig=/etc/kubernetes/admin.conf wait \\
      --for=condition=Ready \\
      -n kube-system \\
      pod -l k8s-app=calico-node \\
      --timeout=600s || {
        echo "‚ö†Ô∏è  AVERTISSEMENT: Calico n'est pas compl√®tement pr√™t apr√®s 10 min"
        echo "üîç √âtat des pods Calico:"
        kubectl --kubeconfig=/etc/kubernetes/admin.conf get pods -n kube-system -l k8s-app=calico-node
      }
  else
    echo "‚úÖ Calico d√©j√† install√©"
  fi

  # ========== G√âN√âRATION DE LA COMMANDE JOIN ==========
  echo "üîó G√©n√©ration du script de join pour les workers..."
  JOIN_CMD=$(kubeadm token create --print-join-command)
  cat >/vagrant/join.sh <<EOF
#!/usr/bin/env bash
set -euxo pipefail
# G√©n√©r√© automatiquement le $(date -u +"%Y-%m-%d %H:%M:%S UTC")
# Commande de join pour rejoindre le cluster #{CLUSTER_NAME}
$JOIN_CMD
EOF
  chmod +x /vagrant/join.sh

  # ========== ATTENTE QUE TOUS LES N≈íUDS SOIENT READY ==========
  echo "‚è≥ Attente que tous les n≈ìuds soient Ready (timeout: 10 min)..."
  kubectl --kubeconfig=/etc/kubernetes/admin.conf wait \\
    --for=condition=Ready \\
    node --all \\
    --timeout=600s || {
      echo "‚ö†Ô∏è  AVERTISSEMENT: Tous les n≈ìuds ne sont pas Ready apr√®s 10 min"
      echo "üîç √âtat du cluster:"
      kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes -o wide
      kubectl --kubeconfig=/etc/kubernetes/admin.conf get pods -A
    }

  # Marquer le provisioning comme termin√©
  touch "$PROVISION_MARKER"
  echo "‚úÖ Control-plane provisionn√© avec succ√®s!"
  echo "üìä √âtat du cluster:"
  kubectl --kubeconfig=/etc/kubernetes/admin.conf get nodes -o wide
SHELL

# ========== SCRIPT DE PROVISIONING WORKER ==========
WORKER_PROVISION = <<-SHELL
  set -euxo pipefail

  # Marqueur d'idempotence
  PROVISION_MARKER="/etc/kubernetes/.worker-provisioned"
  if [ -f "$PROVISION_MARKER" ]; then
    echo "‚è≠Ô∏è  Provisioning worker d√©j√† effectu√©"
    exit 0
  fi

  echo "üë∑ Provisioning du worker node..."

  # Attente de la stabilit√© du control plane (critique!)
  echo "‚è≥ Attente de la stabilit√© du control plane (20s)..."
  sleep 20

  # Arr√™t propre du kubelet
  systemctl stop kubelet 2>/dev/null || true

  # Nettoyage d'un √©ventuel √©tat pr√©c√©dent (idempotence)
  echo "üßπ Nettoyage de l'√©tat kubeadm pr√©c√©dent..."
  kubeadm reset -f || true
  rm -rf /etc/cni/net.d/* || true

  # ========== V√âRIFICATION DE L'API SERVER ==========
  echo "üîç V√©rification de la disponibilit√© de l'API server..."
  API_AVAILABLE=false
  for i in $(seq 1 120); do
    # Note: -k d√©sactive la v√©rification TLS (acceptable en environnement de test)
    if curl -k -s https://#{CONTROL_PLANE_IP}:6443/healthz &>/dev/null; then
      echo "‚úÖ API server disponible apr√®s $i tentative(s)"
      API_AVAILABLE=true
      break
    fi
    echo "‚è≥ Attente de l'API server... ($i/120 - $(($i * 5))s)"
    sleep 5
  done

  if [ "$API_AVAILABLE" = false ]; then
    echo "‚ùå ERREUR: L'API server sur #{CONTROL_PLANE_IP}:6443 n'est pas accessible apr√®s 10 minutes"
    exit 1
  fi

  # ========== V√âRIFICATION DU SCRIPT JOIN ==========
  if [ ! -f /vagrant/join.sh ]; then
    echo "‚ùå ERREUR: /vagrant/join.sh introuvable"
    echo "üîç Le control-plane n'a pas encore g√©n√©r√© le script de join"
    ls -la /vagrant/ || true
    exit 1
  fi

  # ========== EX√âCUTION DU JOIN ==========
  echo "üîó Ex√©cution de la commande kubeadm join..."
  bash -x /vagrant/join.sh

  # V√©rification que le kubelet est actif apr√®s le join
  if ! systemctl is-active --quiet kubelet; then
    echo "‚ùå ERREUR: Le kubelet n'a pas d√©marr√© apr√®s le join"
    systemctl status kubelet --no-pager
    exit 1
  fi

  # Marquer le provisioning comme termin√©
  mkdir -p /etc/kubernetes
  touch "$PROVISION_MARKER"
  echo "‚úÖ Worker provisionn√© avec succ√®s!"
SHELL

# ========== CONFIGURATION VAGRANT ==========
Vagrant.configure("2") do |config|
  config.vm.box = BOX_NAME
  config.vm.synced_folder ".", "/vagrant", disabled: false
  config.vm.synced_folder REPO_ROOT, "/workspace",
                           type: "rsync",
                           rsync__auto: true,
                           rsync__exclude: [".git/", "node_modules/", "*.log"]

  # Configuration SSH
  config.ssh.insert_key = false
  config.vm.boot_timeout = 600

  # ========== D√âFINITION DES N≈íUDS ==========
  NODES.each do |n|
    config.vm.define n[:name], autostart: (n[:name] == "cp1") do |node|
      node.vm.box = BOX_NAME
      node.vm.hostname = "#{CLUSTER_NAME}-#{n[:name]}"
      node.vm.network "private_network", ip: "#{IP_BASE}.#{n[:ip_octet]}"

      # ========== CONFIGURATION PROVIDER ==========
      node.vm.provider "vmware_desktop" do |v|
        v.vmx["memsize"]  = n[:memory].to_s
        v.vmx["numvcpus"] = n[:cpus].to_s
        v.vmx["ethernet0.pcislotnumber"] = "160" # √âvite les warnings r√©seau VMware
        v.gui = false
      end

      # ========== PROVISIONING 1: ATTENTE CLOUD-INIT ==========
      node.vm.provision "cloud-init-wait", type: "shell", privileged: true, inline: <<-SHELL
        set -euxo pipefail
        command -v cloud-init >/dev/null 2>&1 && cloud-init status --wait || true
      SHELL

      # ========== PROVISIONING 2: COMMUN ==========
      node.vm.provision "common", type: "shell", privileged: true, inline: COMMON_PROVISION

      # ========== PROVISIONING 3: CONFIGURATION R√âSEAU ==========
      # Note: Vagrant configure d√©j√† l'IP via config.vm.network "private_network"
      # Ce provisioner v√©rifie juste que la configuration est correcte
      node.vm.provision "network-config", type: "shell", privileged: true, inline: <<-SHELL
        set -euxo pipefail
        
        NODE_IP="#{IP_BASE}.#{n[:ip_octet]}"
        MARKER="/etc/kubernetes/.network-configured"
        
        if [ -f "$MARKER" ]; then
          echo "‚è≠Ô∏è  R√©seau d√©j√† configur√©"
          exit 0
        fi

        echo "üåê V√©rification de la configuration r√©seau..."

        # Vagrant configure automatiquement le private_network
        # On d√©tecte l'interface qui a notre IP cible
        IFACE=$(ip -4 -o addr show | grep "$NODE_IP" | awk '{print $2}')

        if [ -z "$IFACE" ]; then
          echo "‚ö†Ô∏è  Interface avec IP $NODE_IP non trouv√©e, d√©tection automatique..."
          
          # Fallback : chercher une interface qui N'EST PAS la principale (ens160)
          # Sur VMware, c'est typiquement ens224, ens192, ou ens256
          for candidate in ens224 ens256 ens192; do
            if ip link show "$candidate" >/dev/null 2>&1; then
              IFACE="$candidate"
              echo "‚úÖ Interface d√©tect√©e: $IFACE"
              
              # V√©rifier si l'interface a d√©j√† une IP
              CURRENT_IP=$(ip -4 -o addr show "$IFACE" | awk '{print $4}' | cut -d/ -f1)
              
              if [ "$CURRENT_IP" = "$NODE_IP" ]; then
                echo "‚úÖ Interface $IFACE d√©j√† configur√©e avec $NODE_IP"
              elif [ -n "$CURRENT_IP" ]; then
                echo "‚ö†Ô∏è  Interface $IFACE a d√©j√† l'IP $CURRENT_IP, mise √† jour vers $NODE_IP..."
                ip addr flush dev "$IFACE"
                ip addr add "$NODE_IP/24" dev "$IFACE"
              else
                echo "üîß Configuration de l'interface $IFACE avec $NODE_IP..."
                ip link set "$IFACE" up
                ip addr add "$NODE_IP/24" dev "$IFACE"
              fi
              
              break
            fi
          done
        else
          echo "‚úÖ Interface $IFACE d√©j√† configur√©e avec IP $NODE_IP par Vagrant"
        fi

        if [ -z "$IFACE" ]; then
          echo "‚ùå ERREUR: Impossible de trouver l'interface r√©seau"
          echo "üîç Interfaces disponibles:"
          ip -o link show
          echo "üîç Adresses IP:"
          ip -4 -o addr show
          exit 1
        fi

        # Configuration persistante avec netplan (pour survivre aux red√©marrages)
        cat >/etc/netplan/60-private-network.yaml <<EOF
network:
  version: 2
  ethernets:
    $IFACE:
      addresses:
        - $NODE_IP/24
EOF
        chmod 600 /etc/netplan/60-private-network.yaml
        netplan apply || echo "‚ö†Ô∏è  netplan apply a √©chou√© (non bloquant)"

        touch "$MARKER"
        echo "‚úÖ Configuration r√©seau valid√©e pour $IFACE ($NODE_IP)"
      SHELL

      # ========== PROVISIONING 4: CONFIGURATION KUBELET NODE-IP ==========
      node.vm.provision "kubelet-node-ip", type: "shell", privileged: true, inline: <<-SHELL
        set -euxo pipefail
        
        NODE_IP="#{IP_BASE}.#{n[:ip_octet]}"
        MARKER="/etc/kubernetes/.kubelet-nodeip-configured"
        
        if [ -f "$MARKER" ]; then
          echo "‚è≠Ô∏è  Kubelet node-ip d√©j√† configur√©"
          exit 0
        fi

        echo "üîß Configuration du node-ip pour kubelet..."
        
        # Configuration via /etc/default/kubelet (lu par le drop-in officiel)
        cat >/etc/default/kubelet <<EOF
KUBELET_EXTRA_ARGS=--node-ip=$NODE_IP
EOF

        systemctl daemon-reload
        
        touch "$MARKER"
        echo "‚úÖ Kubelet configur√© avec node-ip=$NODE_IP"
      SHELL

      # ========== PROVISIONING 5: R√îLE-SP√âCIFIQUE ==========
      if n[:role] == "control-plane"
        node.vm.provision "init-control-plane", type: "shell", privileged: true, inline: MASTER_PROVISION
      else
        node.vm.provision "join-worker", type: "shell", privileged: true, inline: WORKER_PROVISION
      end

      # ========== PROVISIONING 6: KUBELET-AUTO-CONFIG SERVICE ==========
      node.vm.provision "kubelet-auto-config", type: "shell", privileged: true, inline: <<-SHELL
        set -euxo pipefail

        MARKER="/etc/kubernetes/.kubelet-auto-config-installed"
        
        if [ -f "$MARKER" ]; then
          echo "‚è≠Ô∏è  kubelet-auto-config d√©j√† install√©"
          exit 0
        fi

        echo "üì¶ Installation du service kubelet-auto-config (r√¥le: #{n[:role]})..."

        # V√©rification du montage /workspace
        if [ ! -d /workspace ]; then
          echo "‚ùå ERREUR: /workspace n'est pas mont√©"
          exit 1
        fi

        if [ ! -f /workspace/kubelet_auto_config.sh ]; then
          echo "‚ùå ERREUR: kubelet_auto_config.sh introuvable dans /workspace"
          ls -la /workspace/ || true
          exit 1
        fi

        # Cr√©ation de l'archive et installation
        ARCHIVE="/tmp/reserved-sys-kube.tar.gz"
        tar czf "$ARCHIVE" -C /workspace \\
          kubelet_auto_config.sh \\
          rollback-kubelet-config.sh \\
          remove-kubelet-auto-config.sh \\
          systemd

        rm -rf /usr/local/lib/kubelet-auto-config
        mkdir -p /usr/local/lib/kubelet-auto-config
        tar xzf "$ARCHIVE" -C /usr/local/lib/kubelet-auto-config

        # Installation des scripts
        install -m 0755 /usr/local/lib/kubelet-auto-config/kubelet_auto_config.sh \\
          /usr/local/bin/kubelet_auto_config.sh
        install -m 0755 /usr/local/lib/kubelet-auto-config/rollback-kubelet-config.sh \\
          /usr/local/bin/rollback-kubelet-config.sh
        install -m 0755 /usr/local/lib/kubelet-auto-config/remove-kubelet-auto-config.sh \\
          /usr/local/bin/remove-kubelet-auto-config.sh

        # Installation du service systemd
        if [ ! -x /usr/local/lib/kubelet-auto-config/systemd/install-kubelet-auto-config.sh ]; then
          echo "‚ùå ERREUR: install-kubelet-auto-config.sh introuvable ou non ex√©cutable"
          exit 1
        fi

        /usr/local/lib/kubelet-auto-config/systemd/install-kubelet-auto-config.sh #{n[:role]}

        # V√©rification post-installation
        if ! systemctl is-enabled kubelet-auto-config@#{n[:role]} >/dev/null 2>&1; then
          echo "‚ùå ERREUR: Le service kubelet-auto-config@#{n[:role]} n'est pas activ√©"
          systemctl status kubelet-auto-config@#{n[:role]} --no-pager || true
          exit 1
        fi

        touch "$MARKER"
        echo "‚úÖ Service kubelet-auto-config@#{n[:role]} install√© et activ√©"
      SHELL
    end
  end
end
