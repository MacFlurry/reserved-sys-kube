# Configuration Automatique des R√©servations Kubelet

> Script bash pour configurer dynamiquement `system-reserved` et `kube-reserved` sur des n≈ìuds Kubernetes v1.32+

[![Kubernetes](https://img.shields.io/badge/kubernetes-v1.32-blue.svg)](https://kubernetes.io/)
[![Bash](https://img.shields.io/badge/bash-5.0+-green.svg)](https://www.gnu.org/software/bash/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

---

## üìã Table des mati√®res

- [Vue d'ensemble](#vue-densemble)
- [Pr√©requis](#pr√©requis)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Profils disponibles](#profils-disponibles)
- [Exemples d'utilisation](#exemples-dutilisation)
- [D√©ploiement sur un cluster](#d√©ploiement-sur-un-cluster)
- [Validation post-d√©ploiement](#validation-post-d√©ploiement)
- [Rollback](#rollback)
- [FAQ](#faq)
- [Troubleshooting](#troubleshooting)

---

## üéØ Vue d'ensemble

Ce script automatise la configuration des r√©servations de ressources kubelet (`system-reserved` et `kube-reserved`) en :

- ‚úÖ **D√©tectant automatiquement** les ressources du n≈ìud (vCPU, RAM)
- ‚úÖ **Calculant les r√©servations optimales** selon plusieurs profils (GKE, EKS, Conservative, Minimal)
- ‚úÖ **Adaptant dynamiquement** selon la densit√© de pods cible (via `density-factor`)
- ‚úÖ **G√©n√©rant la configuration kubelet** compl√®te
- ‚úÖ **Appliquant et validant** la configuration

### Pourquoi ce script ?

Les r√©servations `system-reserved` et `kube-reserved` sont **critiques** pour la stabilit√© des n≈ìuds Kubernetes :
- **Sous-dimensionn√©es** ‚Üí OOM kills, √©victions, node NotReady
- **Sur-dimensionn√©es** ‚Üí Gaspillage de capacit√© allocatable

Ce script applique les **formules officielles** document√©es par Google (GKE), Amazon (EKS) et Red Hat (OpenShift).

---

## üîß Pr√©requis

### Syst√®me d'exploitation
- Linux avec systemd (Ubuntu 20.04+, Debian 11+, RHEL 8+, Rocky Linux 8+)
- Noyau Linux 5.x+ (pour cgroups v2, recommand√©)

### Kubernetes
- Version **v1.26+** (test√© sur v1.32)
- Container runtime : **containerd** (recommand√©) ou CRI-O
- Kubelet configur√© avec `cgroupDriver: systemd`

### D√©pendances

Le script n√©cessite les outils suivants :

```bash
# Sur Debian/Ubuntu
sudo apt update
sudo apt install -y bc jq systemd yq

# Sur RHEL/Rocky/CentOS
sudo dnf install -y bc jq systemd yq

# Installer yq (si non disponible dans les repos)
sudo wget https://github.com/mikefarah/yq/releases/latest/download/yq_linux_amd64 -O /usr/bin/yq
sudo chmod +x /usr/bin/yq
```

### Permissions

Le script doit √™tre ex√©cut√© en tant que **root** ou avec **sudo** :
```bash
sudo ./configure-kubelet-reservations.sh
```

---

## üì¶ Installation

### M√©thode 1 : T√©l√©chargement direct

```bash
# T√©l√©charger le script
curl -O https://gitlab.com/omega8280051/reserved-sys-kube/-/raw/main/kubelet_auto_config.sh

# Rendre ex√©cutable
chmod +x configure-kubelet-reservations.sh

# V√©rifier les d√©pendances
./configure-kubelet-reservations.sh --help
```

### M√©thode 2 : Via Git

```bash
git clone https://gitlab.com/omega8280051/reserved-sys-kube.git
cd reserved-sys-kube
chmod +x configure-kubelet-reservations.sh
```

### M√©thode 3 : D√©ploiement sur tous les n≈ìuds

```bash
# Copier le script sur tous les n≈ìuds via SSH
NODES="node1 node2 node3"  # Remplacer par vos n≈ìuds
for node in $NODES; do
    scp configure-kubelet-reservations.sh root@$node:/usr/local/bin/
    ssh root@$node "chmod +x /usr/local/bin/configure-kubelet-reservations.sh"
done
```

---

## üöÄ Utilisation

### Syntaxe g√©n√©rale

```bash
sudo ./configure-kubelet-reservations.sh [OPTIONS]
```

### Options disponibles

| Option | Description | Valeur par d√©faut |
|--------|-------------|-------------------|
| `--profile <profil>` | Profil de calcul : `gke`, `eks`, `conservative`, `minimal` | `gke` |
| `--density-factor <float>` | Multiplicateur pour haute densit√© (1.0 √† 3.0) | `1.0` |
| `--target-pods <int>` | Nombre de pods cible (calcul auto du density-factor) | - |
| `--dry-run` | Affiche la configuration sans l'appliquer | `false` |
| `--backup` | Sauvegarde la configuration existante | `false` |
| `--help` | Affiche l'aide | - |

### Workflow recommand√©

```
1. Test en dry-run        ‚Üí V√©rifier les valeurs calcul√©es
2. Backup                 ‚Üí Sauvegarder la config existante
3. Application            ‚Üí Appliquer la nouvelle config
4. Validation             ‚Üí V√©rifier allocatable et stabilit√©
```

---

## üìö Profils disponibles

### 1. **GKE** (Google Kubernetes Engine) - Recommand√©

**Cas d'usage** : Clusters production g√©n√©ralistes

**Caract√©ristiques** :
- Formules officielles Google Cloud
- √âquilibre stabilit√© / capacit√©
- Test√© √† grande √©chelle (>100k n≈ìuds)

**Exemple** :
```bash
sudo ./configure-kubelet-reservations.sh --profile gke
```

**R√©sultat typique (16 vCPU / 64 GiB)** :
- system-reserved : `300m CPU, 1123Mi RAM`
- kube-reserved : `220m CPU, 959Mi RAM`
- Allocatable : `15480m CPU, 62.08 GiB RAM`

---

### 2. **EKS** (Amazon Elastic Kubernetes Service)

**Cas d'usage** : Clusters AWS, compatibilit√© EKS

**Caract√©ristiques** :
- Formules officielles Amazon EKS
- R√©servations par paliers (< 8 vCPU, 8-32 vCPU, > 32 vCPU)

**Exemple** :
```bash
sudo ./configure-kubelet-reservations.sh --profile eks
```

---

### 3. **Conservative** (OpenShift-like)

**Cas d'usage** : Environnements critiques, workloads sensibles

**Caract√©ristiques** :
- Inspir√© de Red Hat OpenShift
- R√©servations major√©es (+30-50% vs GKE)
- Privil√©gie la stabilit√© sur la capacit√©

**Exemple** :
```bash
sudo ./configure-kubelet-reservations.sh --profile conservative
```

**R√©sultat typique (16 vCPU / 64 GiB)** :
- system-reserved : `660m CPU, 2355Mi RAM`
- kube-reserved : `740m CPU, 4301Mi RAM`
- Allocatable : `14600m CPU, 57.52 GiB RAM`

---

### 4. **Minimal**

**Cas d'usage** : Environnements dev/test, maximiser allocatable

**Caract√©ristiques** :
- R√©servations minimales
- ‚ö†Ô∏è **Attention** : Monitoring requis, risque instabilit√©

**Exemple** :
```bash
sudo ./configure-kubelet-reservations.sh --profile minimal --dry-run
```

---

## üéõÔ∏è Density-factor : Adapter selon la densit√© de pods

### Concept

Le **density-factor** est un multiplicateur appliqu√© aux r√©servations pour compenser la charge kubelet selon le nombre de pods par n≈ìud.

### Tableau de recommandations

| Pods/n≈ìud | Density-factor | Commande |
|-----------|----------------|----------|
| **0-30** (faible) | `1.0` (baseline) | Par d√©faut |
| **31-50** (standard) | `1.1` (+10%) | `--density-factor 1.1` |
| **51-80** (√©lev√©e) | `1.2` (+20%) | `--density-factor 1.2` |
| **81-110** (tr√®s √©lev√©e) | `1.5` (+50%) | `--density-factor 1.5` ou `--target-pods 110` |
| **>110** (extr√™me) | `2.0` (+100%) | `--density-factor 2.0` + augmenter `maxPods` |

### Calcul automatique

Le script peut **calculer automatiquement** le density-factor :

```bash
# Cluster avec 110 pods/n≈ìud maximum
sudo ./configure-kubelet-reservations.sh --profile conservative --target-pods 110

# Le script calcule automatiquement : density-factor = 1.5
```

### Exemples concrets

#### Cluster avec 20 pods/n≈ìud (faible densit√©)
```bash
# Pas de facteur n√©cessaire
sudo ./configure-kubelet-reservations.sh --profile gke
```

#### Cluster avec 80 pods/n≈ìud (haute densit√©)
```bash
# Facteur 1.2 recommand√©
sudo ./configure-kubelet-reservations.sh --profile conservative --density-factor 1.2
```

#### Cluster avec 110 pods/n≈ìud (limite maximale)
```bash
# Calcul automatique du facteur
sudo ./configure-kubelet-reservations.sh --profile conservative --target-pods 110 --backup

# Ou manuellement
sudo ./configure-kubelet-reservations.sh --profile conservative --density-factor 1.5 --backup
```

---

## üìñ Exemples d'utilisation

### Exemple 1 : Premier test (dry-run)

```bash
# Voir la configuration qui serait appliqu√©e, sans toucher au syst√®me
sudo ./configure-kubelet-reservations.sh --dry-run

# Sortie :
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#   CONFIGURATION KUBELET - R√âSERVATIONS CALCUL√âES
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 
# Configuration n≈ìud:
#   vCPU:              16
#   RAM:               64 GiB
#   Profil:            gke
#   Density-factor:    1.0
# [...]
```

### Exemple 2 : Configuration standard production

```bash
# N≈ìud g√©n√©raliste, 30-50 pods maximum
sudo ./configure-kubelet-reservations.sh --profile gke --backup

# V√©rifier les logs kubelet
sudo journalctl -u kubelet -f
```

### Exemple 3 : Cluster haute densit√© (110 pods/n≈ìud)

```bash
# √âtape 1 : Dry-run pour v√©rifier
sudo ./configure-kubelet-reservations.sh \
  --profile conservative \
  --target-pods 110 \
  --dry-run

# √âtape 2 : Application avec backup
sudo ./configure-kubelet-reservations.sh \
  --profile conservative \
  --target-pods 110 \
  --backup

# √âtape 3 : Validation
kubectl describe node $(hostname) | grep -A 10 Allocatable
```

### Exemple 4 : Configuration personnalis√©e

```bash
# Profil conservative avec facteur custom
sudo ./configure-kubelet-reservations.sh \
  --profile conservative \
  --density-factor 1.3 \
  --backup
```

### Exemple 5 : Environnement dev/test (minimal)

```bash
# Maximiser la capacit√© allocatable (avec pr√©caution)
sudo ./configure-kubelet-reservations.sh \
  --profile minimal \
  --dry-run  # Toujours tester d'abord !
```

---

## üåê D√©ploiement sur un cluster

### Architecture cible

**Exemple** : Cluster de 220 n≈ìuds avec 110 pods/n≈ìud
- **Total** : 24,200 pods dans le cluster
- **Profil** : Conservative + density-factor 1.5

### Strat√©gie de d√©ploiement progressive

```
Phase 1 : 1 n≈ìud pilote     ‚Üí Validation 24-48h
Phase 2 : 10% (22 n≈ìuds)    ‚Üí Validation 7 jours
Phase 3 : 50% (110 n≈ìuds)   ‚Üí Validation 7 jours
Phase 4 : 100% (220 n≈ìuds)  ‚Üí Rollout complet
```

---

### M√©thode 1 : D√©ploiement manuel (petit cluster)

```bash
#!/bin/bash
# deploy-manual.sh

NODES="node1 node2 node3 node4 node5"  # Liste de vos n≈ìuds
PROFILE="conservative"
TARGET_PODS="110"

for node in $NODES; do
    echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
    echo "Configuration du n≈ìud : $node"
    echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
    
    # Copier le script
    scp configure-kubelet-reservations.sh root@$node:/tmp/
    
    # Ex√©cuter
    ssh root@$node "chmod +x /tmp/configure-kubelet-reservations.sh && \
                    /tmp/configure-kubelet-reservations.sh \
                    --profile $PROFILE \
                    --target-pods $TARGET_PODS \
                    --backup"
    
    # V√©rifier le status
    ssh root@$node "systemctl is-active kubelet"
    
    echo ""
    echo "‚úì N≈ìud $node configur√©"
    echo ""
    sleep 5
done

echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
echo "D√©ploiement termin√© sur tous les n≈ìuds"
echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
```

**Ex√©cution** :
```bash
chmod +x deploy-manual.sh
./deploy-manual.sh
```

---

### M√©thode 2 : D√©ploiement via Ansible (recommand√©)

**Fichier** : `deploy-kubelet-config.yml`

```yaml
---
- name: Configuration des r√©servations kubelet sur tous les n≈ìuds
  hosts: k8s_workers
  become: yes
  vars:
    profile: "conservative"
    target_pods: 110
    backup_enabled: true
  
  tasks:
    - name: V√©rifier les d√©pendances
      package:
        name:
          - bc
          - jq
          - systemd
        state: present
    
    - name: Copier le script de configuration
      copy:
        src: configure-kubelet-reservations.sh
        dest: /usr/local/bin/configure-kubelet-reservations.sh
        mode: '0755'
        owner: root
        group: root
    
    - name: Ex√©cuter la configuration (dry-run)
      command: >
        /usr/local/bin/configure-kubelet-reservations.sh
        --profile {{ profile }}
        --target-pods {{ target_pods }}
        --dry-run
      register: dryrun_output
      changed_when: false
    
    - name: Afficher le r√©sultat du dry-run
      debug:
        var: dryrun_output.stdout_lines
    
    - name: Pause pour validation
      pause:
        prompt: "V√©rifiez les r√©sultats dry-run. Continuer ? (Ctrl+C pour annuler)"
      when: ansible_check_mode == false
    
    - name: Appliquer la configuration kubelet
      command: >
        /usr/local/bin/configure-kubelet-reservations.sh
        --profile {{ profile }}
        --target-pods {{ target_pods }}
        {% if backup_enabled %}--backup{% endif %}
      register: apply_output
    
    - name: Afficher le r√©sultat de l'application
      debug:
        var: apply_output.stdout_lines
    
    - name: V√©rifier le status kubelet
      systemd:
        name: kubelet
        state: started
        enabled: yes
      register: kubelet_status
    
    - name: Attendre la stabilisation
      wait_for:
        timeout: 30
      delegate_to: localhost
    
    - name: V√©rifier que le n≈ìud est Ready
      shell: kubectl get node {{ inventory_hostname }} -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}'
      delegate_to: localhost
      register: node_ready
      until: node_ready.stdout == "True"
      retries: 6
      delay: 10
    
    - name: Afficher l'allocatable du n≈ìud
      shell: kubectl describe node {{ inventory_hostname }} | grep -A 10 "Allocatable:"
      delegate_to: localhost
      register: allocatable
    
    - debug:
        var: allocatable.stdout_lines

- name: Rapport final
  hosts: localhost
  gather_facts: no
  tasks:
    - name: R√©capitulatif des n≈ìuds configur√©s
      debug:
        msg: "Configuration appliqu√©e sur {{ groups['k8s_workers'] | length }} n≈ìuds"
```

**Inventory Ansible** : `inventory.ini`

```ini
[k8s_workers]
node1.example.com
node2.example.com
node3.example.com
# ... (tous vos n≈ìuds)

[k8s_workers:vars]
ansible_user=root
ansible_ssh_private_key_file=~/.ssh/id_rsa
```

**Ex√©cution** :

```bash
# Dry-run sur tous les n≈ìuds
ansible-playbook -i inventory.ini deploy-kubelet-config.yml --check

# Application r√©elle
ansible-playbook -i inventory.ini deploy-kubelet-config.yml

# Application sur un groupe sp√©cifique (phase progressive)
ansible-playbook -i inventory.ini deploy-kubelet-config.yml --limit "node[1:22]"
```

---

### M√©thode 3 : D√©ploiement via DaemonSet (avanc√©)

‚ö†Ô∏è **Attention** : Cette m√©thode n√©cessite des privil√®ges √©lev√©s (hostPath, privileged)

**Fichier** : `kubelet-config-daemonset.yaml`

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kubelet-config-updater
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: kubelet-config-updater
  template:
    metadata:
      labels:
        app: kubelet-config-updater
    spec:
      hostNetwork: true
      hostPID: true
      priorityClassName: system-node-critical
      tolerations:
      - effect: NoSchedule
        operator: Exists
      containers:
      - name: updater
        image: ubuntu:22.04
        command:
        - /bin/bash
        - -c
        - |
          # Installation des d√©pendances
          apt update && apt install -y bc jq systemd
          
          # Copier le script depuis ConfigMap
          cp /scripts/configure-kubelet-reservations.sh /tmp/
          chmod +x /tmp/configure-kubelet-reservations.sh
          
          # Ex√©cuter la configuration
          chroot /host /tmp/configure-kubelet-reservations.sh \
            --profile conservative \
            --target-pods 110 \
            --backup
          
          # Marquer comme termin√©
          echo "Configuration termin√©e sur $(hostname)"
          sleep infinity
        securityContext:
          privileged: true
        volumeMounts:
        - name: host-root
          mountPath: /host
        - name: scripts
          mountPath: /scripts
      volumes:
      - name: host-root
        hostPath:
          path: /
      - name: scripts
        configMap:
          name: kubelet-config-script
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kubelet-config-script
  namespace: kube-system
data:
  configure-kubelet-reservations.sh: |
    # Coller ici le contenu du script bash
```

**D√©ploiement** :
```bash
kubectl apply -f kubelet-config-daemonset.yaml

# Suivre les logs
kubectl logs -n kube-system -l app=kubelet-config-updater -f

# Supprimer apr√®s d√©ploiement
kubectl delete daemonset -n kube-system kubelet-config-updater
```

---

## ‚úÖ Validation post-d√©ploiement

### 1. V√©rifier l'allocatable sur tous les n≈ìuds

```bash
kubectl get nodes -o custom-columns=\
NAME:.metadata.name,\
CPU-CAP:.status.capacity.cpu,\
CPU-ALLOC:.status.allocatable.cpu,\
MEM-CAP:.status.capacity.memory,\
MEM-ALLOC:.status.allocatable.memory
```

**Sortie attendue** :
```
NAME      CPU-CAP   CPU-ALLOC   MEM-CAP      MEM-ALLOC
node1     16        15480m      67108864Ki   63572992Ki
node2     16        15480m      67108864Ki   63572992Ki
node3     16        15480m      67108864Ki   63572992Ki
```

### 2. V√©rifier qu'aucun n≈ìud n'est NotReady

```bash
kubectl get nodes

# Tous les n≈ìuds doivent √™tre Ready
# Si un n≈ìud est NotReady, v√©rifier les logs :
kubectl describe node <node-name>
```

### 3. V√©rifier les cgroups sur un n≈ìud

```bash
# Se connecter √† un n≈ìud
ssh node1

# V√©rifier la hi√©rarchie cgroups
systemd-cgls | grep -E "(system.slice|kubepods.slice|kubelet.slice)"

# Sortie attendue :
# ‚îú‚îÄsystem.slice
# ‚îÇ ‚îú‚îÄcontainerd.service
# ‚îÇ ‚îî‚îÄ...
# ‚îú‚îÄkubelet.slice
# ‚îÇ ‚îî‚îÄkubelet.service
# ‚îî‚îÄkubepods.slice
#   ‚îú‚îÄkubepods-burstable.slice
#   ‚îî‚îÄkubepods-besteffort.slice
```

### 4. V√©rifier les m√©triques kubelet

```bash
# Sur un n≈ìud
curl -s http://localhost:10255/metrics | grep -E "(kubelet_runtime_operations|kubelet_pleg)"

# M√©triques cl√©s :
# - kubelet_pleg_relist_duration_seconds : doit √™tre < 5s
# - kubelet_runtime_operations_duration_seconds : doit √™tre < 2s
```

### 5. V√©rifier les √©victions

```bash
# Aucune √©viction due √† pression m√©moire ne devrait appara√Ætre
kubectl get events --all-namespaces --field-selector reason=Evicted

# Si des √©victions apparaissent, augmenter les r√©servations
```

### 6. Test de charge (optionnel)

```bash
# D√©ployer un workload de test
kubectl create deployment stress-test --image=polinux/stress \
  --replicas=10 -- stress --cpu 1 --vm 1 --vm-bytes 512M --timeout 300s

# Observer la stabilit√© des n≈ìuds
watch -n 2 "kubectl top nodes"

# Nettoyer
kubectl delete deployment stress-test
```

---

## üîÑ Rollback

### En cas de probl√®me

#### 1. Restaurer depuis le backup

```bash
# Le script cr√©e automatiquement un backup si --backup est utilis√©
# Format : /var/lib/kubelet/config.yaml.backup.YYYYMMDD_HHMMSS

# Lister les backups
ls -lh /var/lib/kubelet/config.yaml.backup.*

# Restaurer le dernier backup
LATEST_BACKUP=$(ls -t /var/lib/kubelet/config.yaml.backup.* | head -1)
sudo cp "$LATEST_BACKUP" /var/lib/kubelet/config.yaml

# Red√©marrer kubelet
sudo systemctl restart kubelet
```

#### 2. Rollback automatique via script

```bash
#!/bin/bash
# rollback-kubelet-config.sh

LATEST_BACKUP=$(ls -t /var/lib/kubelet/config.yaml.backup.* 2>/dev/null | head -1)

if [[ -z "$LATEST_BACKUP" ]]; then
    echo "Aucun backup trouv√©"
    exit 1
fi

echo "Restauration depuis : $LATEST_BACKUP"
sudo cp "$LATEST_BACKUP" /var/lib/kubelet/config.yaml
sudo systemctl restart kubelet

echo "Rollback termin√©. V√©rifiez le status :"
sudo systemctl status kubelet
```

#### 3. Configuration manuelle d'urgence

Si le kubelet ne d√©marre plus :

```bash
# √âditer manuellement la config
sudo vi /var/lib/kubelet/config.yaml

# Supprimer ou ajuster les sections systemReserved et kubeReserved
# Exemple minimal qui fonctionne toujours :
# systemReserved:
#   cpu: "100m"
#   memory: "512Mi"
# kubeReserved:
#   cpu: "100m"
#   memory: "512Mi"

# Red√©marrer
sudo systemctl restart kubelet
sudo journalctl -u kubelet -f
```

---

## ‚ùì FAQ

### Q1 : Le script modifie-t-il d'autres param√®tres kubelet ?

**R** : Non, le script g√©n√®re une configuration **compl√®te** mais ne modifie que :
- `systemReserved`
- `kubeReserved`
- `enforceNodeAllocatable`
- Les cgroups associ√©s
- Les seuils d'√©viction (valeurs standard)

Tous les autres param√®tres conservent leurs valeurs par d√©faut Kubernetes.

### Q2 : Puis-je ex√©cuter le script plusieurs fois ?

**R** : Oui, le script est **idempotent**. Vous pouvez le relancer sans risque. Utilisez `--backup` pour conserver un historique.

### Q3 : Que se passe-t-il si mes pods d√©passent l'allocatable apr√®s modification ?

**R** : Kubernetes **n'√©vincera PAS** les pods d√©j√† running. Seuls les nouveaux pods seront soumis aux nouvelles limites. Pour forcer un r√©ajustement :

```bash
# Drainer le n≈ìud (optionnel)
kubectl drain <node-name> --ignore-daemonsets --delete-emptydir-data

# Appliquer la config
sudo ./configure-kubelet-reservations.sh --profile conservative --target-pods 110 --backup

# Rendre le n≈ìud schedulable
kubectl uncordon <node-name>
```

### Q4 : Comment choisir entre GKE et Conservative ?

| Crit√®re | GKE | Conservative |
|---------|-----|--------------|
| **Environnement** | Prod g√©n√©raliste | Critique (finance, sant√©) |
| **Densit√©** | < 80 pods/n≈ìud | > 80 pods/n≈ìud ou haute criticit√© |
| **Allocatable** | Maximis√© | R√©duit de ~15% |
| **Stabilit√©** | Excellente | Maximale |
| **Recommandation** | ‚úÖ D√©faut | Workloads sensibles |

### Q5 : Le script fonctionne-t-il avec cgroups v1 ?

**R** : Oui, le script est compatible cgroups v1 et v2. Il d√©tecte automatiquement la version via `systemd`.

### Q6 : Puis-je personnaliser les valeurs calcul√©es ?

**R** : Le script applique des formules √©prouv√©es. Pour des ajustements fins :

1. Utiliser `--dry-run` pour voir les valeurs
2. Modifier manuellement `/var/lib/kubelet/config.yaml` apr√®s ex√©cution
3. Ou √©diter le script (section `calculate_XXX()`)

### Q7 : Comment surveiller l'impact des r√©servations ?

**R** : M√©triques Prometheus √† surveiller :

```promql
# CPU throttling kubelet (doit √™tre < 5%)
rate(container_cpu_cfs_throttled_seconds_total{container="kubelet"}[5m])

# M√©moire disponible n≈ìud (doit √™tre > 1GiB)
node_memory_MemAvailable_bytes / 1024 / 1024 / 1024

# PLEG latency (doit √™tre < 5s)
kubelet_pleg_relist_duration_seconds{quantile="0.99"}
```

---

## üêõ Troubleshooting

### Probl√®me 1 : Kubelet ne d√©marre pas apr√®s application

**Sympt√¥mes** :
```bash
sudo systemctl status kubelet
# ‚óè kubelet.service - kubelet: The Kubernetes Node Agent
#    Active: failed (Result: exit-code)
```

**Solution** :
```bash
# V√©rifier les logs
sudo journalctl -u kubelet -n 100 --no-pager

# Erreurs fr√©quentes :
# 1. "failed to parse kubelet config file"
#    ‚Üí Syntaxe YAML invalide dans /var/lib/kubelet/config.yaml
#    ‚Üí Restaurer le backup

# 2. "failed to create cgroup"
#    ‚Üí V√©rifier que systemd est bien le cgroup driver
#    ‚Üí V√©rifier : cat /var/lib/kubelet/config.yaml | grep cgroupDriver

# 3. "reservations exceed node capacity"
#    ‚Üí Les r√©servations sont trop √©lev√©es
#    ‚Üí Utiliser --profile minimal ou r√©duire --density-factor
```

### Probl√®me 2 : Allocatable trop faible, pas assez de place pour les pods

**Sympt√¥mes** :
```bash
kubectl describe node <node>
# Allocatable:
#   cpu: 100m  # Presque rien !
#   memory: 1Gi
```

**Cause** : R√©servations trop √©lev√©es (profil conservative + density-factor trop grand)

**Solution** :
```bash
# 1. V√©rifier les r√©servations actuelles
sudo cat /var/lib/kubelet/config.yaml | grep -A 3 "Reserved:"

# 2. Reconfigurer avec un profil moins conservateur
sudo ./configure-kubelet-reservations.sh --profile gke --backup

# 3. Ou r√©duire le density-factor
sudo ./configure-kubelet-reservations.sh --profile conservative --density-factor 1.2 --backup
```

### Probl√®me 3 : N≈ìud devient NotReady apr√®s configuration

**Sympt√¥mes** :
```bash
kubectl get nodes
# NAME    STATUS     ROLES    AGE   VERSION
# node1   NotReady   <none>   10d   v1.32.0
```

**Diagnostic** :
```bash
# 1. V√©rifier le kubelet
ssh node1 "sudo systemctl status kubelet"

# 2. V√©rifier les conditions du n≈ìud
kubectl describe node node1 | grep -A 20 "Conditions:"

# Causes fr√©quentes :
# - MemoryPressure: True    ‚Üí system-reserved m√©moire trop faible
# - DiskPressure: True      ‚Üí ephemeral-storage mal configur√©
# - NetworkUnavailable      ‚Üí Probl√®me CNI (non li√© au script)
```

**Solution** :
```bash
# Augmenter les r√©servations
ssh node1 "sudo /usr/local/bin/configure-kubelet-reservations.sh \
  --profile conservative \
  --density-factor 1.5 \
  --backup"
```

### Probl√®me 4 : √âvictions fr√©quentes apr√®s d√©ploiement

**Sympt√¥mes** :
```bash
kubectl get events --field-selector reason=Evicted
# REASON    MESSAGE
# Evicted   The node was low on resource: memory
```

**Diagnostic** :
```bash
# V√©rifier la pression m√©moire sur les n≈ìuds affect√©s
ssh node1 "cat /sys/fs/cgroup/kubepods.slice/memory.pressure"

# V√©rifier la m√©moire disponible
ssh node1 "free -h"
```

**Solution** :
```bash
# Augmenter system-reserved et kube-reserved
sudo ./configure-kubelet-reservations.sh \
  --profile conservative \
  --density-factor 1.5 \
  --backup

# OU ajuster manuellement les seuils d'√©viction
sudo vi /var/lib/kubelet/config.yaml
# Modifier :
# evictionHard:
#   memory.available: "1Gi"  # Au lieu de 500Mi
```

### Probl√®me 5 : Script √©choue avec "command not found"

**Sympt√¥mes** :
```bash
./configure-kubelet-reservations.sh
# line 42: bc: command not found
```

**Solution** :
```bash
# Installer les d√©pendances manquantes
# Ubuntu/Debian
sudo apt update && sudo apt install -y bc jq systemd

# RHEL/Rocky/CentOS
sudo dnf install -y bc jq systemd

# V√©rifier
which bc jq systemctl
```

### Probl√®me 6 : Permission denied lors de l'ex√©cution

**Sympt√¥mes** :
```bash
./configure-kubelet-reservations.sh
# bash: ./configure-kubelet-reservations.sh: Permission denied
```

**Solution** :
```bash
# Rendre le script ex√©cutable
chmod +x configure-kubelet-reservations.sh

# Ex√©cuter avec sudo
sudo ./configure-kubelet-reservations.sh
```

### Probl√®me 7 : Les cgroups ne sont pas cr√©√©s

**Sympt√¥mes** :
```bash
systemd-cgls | grep kubelet.slice
# (aucun r√©sultat)
```

**Diagnostic** :
```bash
# V√©rifier la configuration kubelet
sudo cat /var/lib/kubelet/config.yaml | grep -E "(enforceNodeAllocatable|Cgroup)"

# V√©rifier les logs
sudo journalctl -u kubelet | grep -i cgroup
```

**Solution** :
```bash
# S'assurer que enforceNodeAllocatable contient bien :
# - "pods"
# - "system-reserved"
# - "kube-reserved"

# R√©appliquer la configuration
sudo ./configure-kubelet-reservations.sh --profile conservative --backup
```

### Probl√®me 8 : Valeurs diff√©rentes entre n≈ìuds du m√™me type

**Sympt√¥mes** :
```bash
# node1 : Allocatable 15480m CPU
# node2 : Allocatable 15200m CPU (m√™me config mat√©rielle)
```

**Cause** : Le script a √©t√© ex√©cut√© avec des param√®tres diff√©rents

**Solution** :
```bash
# Standardiser sur tous les n≈ìuds
ansible all -i inventory.ini -m shell -a \
  "/usr/local/bin/configure-kubelet-reservations.sh \
  --profile conservative \
  --target-pods 110 \
  --backup"
```

---

## üìä Monitoring et m√©triques

### Dashboards Grafana recommand√©s

#### Dashboard 1 : Vue d'ensemble des r√©servations

**M√©triques Prometheus** :
```promql
# Allocatable CPU par n≈ìud
kube_node_status_allocatable{resource="cpu",unit="core"}

# Allocatable Memory par n≈ìud
kube_node_status_allocatable{resource="memory",unit="byte"} / 1024 / 1024 / 1024

# Capacity vs Allocatable (ratio de r√©servation)
(kube_node_status_capacity{resource="cpu"} - kube_node_status_allocatable{resource="cpu"}) 
/ kube_node_status_capacity{resource="cpu"} * 100
```

#### Dashboard 2 : Sant√© kubelet

```promql
# PLEG latency (doit √™tre < 5s)
histogram_quantile(0.99, 
  rate(kubelet_pleg_relist_duration_seconds_bucket[5m]))

# Throttling CPU kubelet
rate(container_cpu_cfs_throttled_seconds_total{
  container="kubelet"
}[5m]) * 100

# M√©moire RSS kubelet
process_resident_memory_bytes{job="kubelet"} / 1024 / 1024
```

#### Dashboard 3 : √âvictions

```promql
# Nombre d'√©victions par raison
sum by (reason) (kube_pod_status_reason{reason=~"Evicted|OutOf.*"})

# Taux d'√©victions
rate(kube_pod_status_reason{reason="Evicted"}[5m]) * 60
```

### Alertes recommand√©es

**Fichier** : `kubelet-reservations-alerts.yaml`

```yaml
groups:
- name: kubelet-reservations
  interval: 30s
  rules:
  
  # Alerte : Kubelet CPU throttling √©lev√©
  - alert: KubeletHighCPUThrottling
    expr: |
      rate(container_cpu_cfs_throttled_seconds_total{container="kubelet"}[5m]) > 0.1
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Kubelet throttling CPU √©lev√© sur {{ $labels.node }}"
      description: "Le kubelet sur {{ $labels.node }} subit un throttling CPU de {{ $value | humanizePercentage }}. Augmentez kube-reserved CPU."
  
  # Alerte : PLEG latency trop √©lev√©e
  - alert: KubeletPLEGHighLatency
    expr: |
      histogram_quantile(0.99, 
        rate(kubelet_pleg_relist_duration_seconds_bucket[5m])) > 5
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "PLEG latency √©lev√©e sur {{ $labels.node }}"
      description: "P99 PLEG latency = {{ $value }}s (seuil: 5s). Consid√©rez augmenter kube-reserved ou r√©duire la densit√© de pods."
  
  # Alerte : M√©moire kubelet √©lev√©e
  - alert: KubeletHighMemoryUsage
    expr: |
      process_resident_memory_bytes{job="kubelet"} / 1024 / 1024 / 1024 > 4
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Consommation m√©moire kubelet √©lev√©e sur {{ $labels.instance }}"
      description: "Kubelet utilise {{ $value | humanize }}GiB de RAM. Augmentez kube-reserved memory."
  
  # Alerte : √âvictions fr√©quentes
  - alert: FrequentPodEvictions
    expr: |
      rate(kube_pod_status_reason{reason="Evicted"}[15m]) * 60 > 5
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "√âvictions fr√©quentes d√©tect√©es"
      description: "{{ $value | humanize }} √©victions/min. V√©rifiez les r√©servations system-reserved et kube-reserved."
  
  # Alerte : Allocatable tr√®s faible
  - alert: NodeLowAllocatable
    expr: |
      (kube_node_status_allocatable{resource="cpu"} / 
       kube_node_status_capacity{resource="cpu"}) < 0.8
    for: 30m
    labels:
      severity: warning
    annotations:
      summary: "Allocatable CPU faible sur {{ $labels.node }}"
      description: "Seulement {{ $value | humanizePercentage }} de CPU allocatable. R√©servations potentiellement trop √©lev√©es."
```

---

## üîê S√©curit√© et bonnes pratiques

### 1. Permissions du script

```bash
# Le script doit appartenir √† root et ne pas √™tre modifiable par d'autres
sudo chown root:root configure-kubelet-reservations.sh
sudo chmod 750 configure-kubelet-reservations.sh

# V√©rifier
ls -l configure-kubelet-reservations.sh
# -rwxr-x--- 1 root root 28472 Jan 20 10:30 configure-kubelet-reservations.sh
```

### 2. Audit trail

```bash
# Toutes les modifications sont loggu√©es dans syslog
sudo grep "configure-kubelet-reservations" /var/log/syslog

# Ou journalctl
sudo journalctl -t configure-kubelet-reservations
```

### 3. Validation avant production

**Checklist** :
- [ ] Test√© en dry-run sur 1 n≈ìud de dev
- [ ] Test√© en r√©el sur 1 n≈ìud de dev pendant 24h
- [ ] V√©rifi√© allocatable, pas d'√©victions
- [ ] Test√© workload r√©el (charge progressive)
- [ ] Valid√© par l'√©quipe infra/ops
- [ ] Documentation mise √† jour
- [ ] Proc√©dure de rollback test√©e

### 4. Versioning du script

```bash
# Ajouter un num√©ro de version dans le script
VERSION="1.0.0"

# Commit dans Git
git add configure-kubelet-reservations.sh
git commit -m "feat: script configuration kubelet v1.0.0"
git tag v1.0.0
git push origin v1.0.0
```

---

## üìö Ressources suppl√©mentaires

### Documentation officielle Kubernetes

- [Reserve Compute Resources](https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/)
- [Node Allocatable Resources](https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable)
- [Kubelet Configuration Reference](https://kubernetes.io/docs/reference/config-api/kubelet-config.v1beta1/)

### Documentation cloud providers

- [GKE Node Allocatable](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture#node_allocatable_resources)
- [EKS Allocatable Capacity](https://docs.aws.amazon.com/eks/latest/userguide/allocatable-capacity.html)
- [AKS Resource Reservations](https://learn.microsoft.com/en-us/azure/aks/concepts-clusters-workloads#resource-reservations)

### Benchmarks et √©tudes

- [Kubernetes SIG Scalability Thresholds](https://github.com/kubernetes/community/blob/master/sig-scalability/configs-and-limits/thresholds.md)
- [CNCF Cloud Native Landscape](https://landscape.cncf.io/)

---

## ü§ù Contribution

### Signaler un bug

Ouvrez une issue sur GitHub avec :
- Version du script (voir `--help`)
- Version Kubernetes (`kubectl version`)
- OS et version (`cat /etc/os-release`)
- Logs complets (`journalctl -u kubelet`)

### Proposer une am√©lioration

1. Fork le repository
2. Cr√©ez une branche (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Committez (`git commit -am 'feat: ajout fonctionnalit√© X'`)
4. Push (`git push origin feature/nouvelle-fonctionnalite`)
5. Ouvrez une Pull Request

---

## üìù Changelog

### v2.0.0-production (2025-10-21)

**üéØ Production-Ready Enhancements** :
- ‚ú® **Input Validation**: Comprehensive validation for all command-line arguments
  - Profile validation with clear error messages
  - Density-factor bounds checking (0.1-5.0, recommended 0.5-3.0)
  - Target-pods positive integer validation
- ‚ú® **Improved RAM Detection**: Fixed RAM detection using MiB for accuracy (fixes rounding issues)
- ‚ú® **Dynamic Eviction Thresholds**: Eviction thresholds now scale with node size
  - Small nodes (<8 GiB): 250Mi hard / 500Mi soft
  - Medium nodes (8-32 GiB): 500Mi hard / 1Gi soft
  - Large nodes (32-64 GiB): 1Gi hard / 2Gi soft
  - XL nodes (>64 GiB): 2Gi hard / 4Gi soft
- ‚ú® **Cgroup Verification & Creation**: Automatic detection and creation of required cgroups
  - Detects cgroup v1 vs v2
  - Creates kubelet.slice if missing
  - Validates system.slice existence
- ‚ú® **Automatic Rollback**: Built-in rollback mechanism on failure
  - Automatic backup before changes
  - Rollback on kubelet restart failure
  - Rollback on stability check failure (15s wait)
  - Cleanup of temporary backups on success
- ‚ú® **YAML Validation**: Pre-flight validation before applying config
  - Validates YAML syntax with yq
  - Checks apiVersion and kind fields
  - Prevents invalid configs from breaking kubelet
- ‚ú® **Better Error Handling**: Fixed arithmetic expressions and improved reliability
  - Fixed bc comparison in density-factor check
  - Added zero-division protections
  - Better error messages throughout

**üîß Code Quality** :
- üêõ Fixed arithmetic expression for density factor comparison (line 717)
- üêõ Fixed RAM detection precision issues
- üîí Enhanced security with automatic backups
- üìù Added VERSION constant (2.0.0-production)
- üìù Updated documentation headers

**üìö Documentation** :
- üìö Updated README with v2.0.0 changes
- üìö Added yq dependency requirement
- üìö Improved usage examples

### v1.0.0 (2025-01-20)

**Ajouts** :
- ‚ú® D√©tection automatique des ressources (vCPU, RAM)
- ‚ú® 4 profils de calcul (GKE, EKS, Conservative, Minimal)
- ‚ú® Calcul automatique du density-factor via `--target-pods`
- ‚ú® Mode `--dry-run` pour tester sans appliquer
- ‚ú® Option `--backup` pour sauvegarder la config existante
- ‚ú® Validation post-configuration (kubelet status)
- ‚ú® Affichage d√©taill√© des r√©servations et allocatable
- ‚ú® Support cgroups v1 et v2
- ‚ú® Compatible systemd

**Documentation** :
- üìö README complet avec exemples
- üìö Guide de d√©ploiement (manuel, Ansible, DaemonSet)
- üìö Section troubleshooting d√©taill√©e
- üìö FAQ et bonnes pratiques

---

## üìÑ Licence

MIT License

Copyright (c) 2025

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

---

## üÜò Support

### Communaut√©

- **GitHub Issues** : [https://gitlab.com/omega8280051/reserved-sys-kube/-/issues](https://gitlab.com)

---

## ‚ú® Cr√©dits

**D√©velopp√© par** : Platform Engineering Team 

**Bas√© sur** :
- Formules officielles Google (GKE)
- Formules officielles Amazon (EKS)
- Recommandations Red Hat (OpenShift)
- Benchmarks Kubernetes SIG Scalability

**Remerciements** :
- Communaut√© Kubernetes
- CNCF (Cloud Native Computing Foundation)
- Contributeurs open source

---

**Note** : Ce script a √©t√© test√© sur les distributions suivantes :
- ‚úÖ Ubuntu 20.04, 22.04, 24.04
- ‚úÖ Debian 11, 12
- ‚úÖ RHEL 8, 9
- ‚úÖ Rocky Linux 8, 9
- ‚úÖ Amazon Linux 2023

**Versions Kubernetes test√©es** :
- ‚úÖ v1.26.x
- ‚úÖ v1.27.x
- ‚úÖ v1.28.x
- ‚úÖ v1.29.x
- ‚úÖ v1.30.x
- ‚úÖ v1.31.x
- ‚úÖ v1.32.x

---

**Derni√®re mise √† jour** : 20 oct 2025  
**Version du README** : 1.0.0  
**Mainteneur** : Platform Engineering Team
