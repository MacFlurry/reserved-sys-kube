# Configuration Automatique des R√©servations Kubelet

> Script bash pour configurer dynamiquement `system-reserved` et `kube-reserved` sur des n≈ìuds Kubernetes v1.32+

[![Kubernetes](https://img.shields.io/badge/kubernetes-v1.32-blue.svg)](https://kubernetes.io/)
[![Bash](https://img.shields.io/badge/bash-5.0+-green.svg)](https://www.gnu.org/software/bash/)
[![License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)

---

## üìã Table des mati√®res

- [Vue d'ensemble](#-vue-densemble)
- [Pr√©requis](#-pr√©requis)
- [Installation](#-installation)
- [Utilisation](#-utilisation)
- [Profils disponibles](#-profils-disponibles)
- [Density-factor](#%EF%B8%8F-density-factor--adapter-selon-la-densit√©-de-pods)
- [Exemples d'utilisation](#-exemples-dutilisation)
- [D√©ploiement sur un cluster](#-d√©ploiement-sur-un-cluster)
- [Validation post-d√©ploiement](#-validation-post-d√©ploiement)
- [Rollback](#-rollback)
- [FAQ](#-faq)
- [Troubleshooting](#-troubleshooting)
- [Monitoring et m√©triques](#-monitoring-et-m√©triques)
- [S√©curit√© et bonnes pratiques](#-s√©curit√©-et-bonnes-pratiques)
- [Ressources suppl√©mentaires](#-ressources-suppl√©mentaires)
- [Contribution](#-contribution)
- [Changelog](#-changelog-et-notes-de-version)
- [Licence](#-licence)
- [Support](#-support)
- [Cr√©dits](#-cr√©dits)

---

## üéØ Vue d'ensemble

Ce script automatise la configuration des r√©servations de ressources kubelet (`system-reserved` et `kube-reserved`) en :

- ‚úÖ **D√©tectant automatiquement** les ressources du n≈ìud (vCPU, RAM)
- ‚úÖ **Calculant les r√©servations optimales** selon plusieurs profils (GKE, EKS, Conservative, Minimal)
- ‚úÖ **Adaptant dynamiquement** selon la densit√© de pods cible (via `density-factor`)
- ‚úÖ **G√©n√©rant la configuration kubelet** compl√®te
- ‚úÖ **Appliquant et validant** la configuration

### Pourquoi ce script ?

Les r√©servations `system-reserved` et `kube-reserved` sont **critiques** pour la stabilit√© des n≈ìuds Kubernetes :
- **Sous-dimensionn√©es** ‚Üí OOM kills, √©victions, node NotReady
- **Sur-dimensionn√©es** ‚Üí Gaspillage de capacit√© allocatable

Ce script applique les **formules officielles** document√©es par Google (GKE), Amazon (EKS) et Red Hat (OpenShift).

---

## üîß Pr√©requis

### Syst√®me d'exploitation
- Ubuntu 20.04+ avec systemd
- Noyau Linux 5.x+ (pour cgroups v2, recommand√©)

### Kubernetes
- Version **v1.26+** (test√© sur v1.32)
- Container runtime : **containerd** (recommand√©) ou CRI-O
- Kubelet configur√© avec `cgroupDriver: systemd`

### D√©pendances

Le script n√©cessite les outils suivants :

```bash
sudo apt update
sudo apt install -y bc jq systemd yq
```

### Permissions

Le script doit √™tre ex√©cut√© en tant que **root** ou avec **sudo** :
```bash
sudo ./kubelet_auto_config.sh
```

---

## üì¶ Installation

### M√©thode 1 : T√©l√©chargement direct

```bash
# T√©l√©charger le script
curl -O https://gitlab.com/omega8280051/reserved-sys-kube/-/raw/main/kubelet_auto_config.sh

# Rendre ex√©cutable
chmod +x kubelet_auto_config.sh

# V√©rifier les d√©pendances
./kubelet_auto_config.sh --help
```

### M√©thode 2 : Via Git

```bash
git clone https://gitlab.com/omega8280051/reserved-sys-kube.git
cd reserved-sys-kube
chmod +x kubelet_auto_config.sh
```

### M√©thode 3 : D√©ploiement sur tous les n≈ìuds

```bash
# Copier le script sur tous les n≈ìuds via SSH
NODES="node1 node2 node3"  # Remplacer par vos n≈ìuds
for node in $NODES; do
    scp kubelet_auto_config.sh root@$node:/usr/local/bin/
    ssh root@$node "chmod +x /usr/local/bin/kubelet_auto_config.sh"
done
```

---

## üöÄ Utilisation

### Syntaxe g√©n√©rale

```bash
sudo ./kubelet_auto_config.sh [OPTIONS]
```

### Options disponibles

| Option | Description | Valeur par d√©faut |
|--------|-------------|-------------------|
| `--profile <profil>` | Profil de calcul : `gke`, `eks`, `conservative`, `minimal` | `gke` |
| `--density-factor <float>` | Multiplicateur pour haute densit√© (0.1 √† 5.0, recommand√© 0.5-3.0) | `1.0` |
| `--target-pods <int>` | Nombre de pods cible (calcul auto du density-factor) | - |
| `--node-type <type>` | Type de n≈ìud : `control-plane`, `worker`, `auto` (d√©tection auto) | `auto` |
| `--dry-run` | Affiche la configuration sans l'appliquer | `false` |
| `--backup` | Cr√©e un backup permanent timestamp√© (en plus des 4 backups rotatifs automatiques) | `false` |
| `--help` | Affiche l'aide | - |

### Workflow recommand√©

```
1. Test en dry-run        ‚Üí V√©rifier les valeurs calcul√©es
2. Backup                 ‚Üí Sauvegarder la config existante
3. Application            ‚Üí Appliquer la nouvelle config
4. Validation             ‚Üí V√©rifier allocatable et stabilit√©
```

---

## üìö Profils disponibles

### 1. **GKE** (Google Kubernetes Engine) - Recommand√©

**Cas d'usage** : Clusters production g√©n√©ralistes

**Caract√©ristiques** :
- Formules officielles Google Cloud
- √âquilibre stabilit√© / capacit√©
- Test√© √† grande √©chelle (>100k n≈ìuds)

**Exemple** :
```bash
sudo ./kubelet_auto_config.sh --profile gke
```

**R√©sultat typique (16 vCPU / 64 GiB)** :
- system-reserved : `300m CPU, 1123Mi RAM`
- kube-reserved : `220m CPU, 959Mi RAM`
- Allocatable : `15480m CPU, 62.08 GiB RAM`

---

### 2. **EKS** (Amazon Elastic Kubernetes Service)

**Cas d'usage** : Clusters AWS, compatibilit√© EKS

**Caract√©ristiques** :
- Formules officielles Amazon EKS
- R√©servations par paliers (< 8 vCPU, 8-32 vCPU, > 32 vCPU)

**Exemple** :
```bash
sudo ./kubelet_auto_config.sh --profile eks
```

---

### 3. **Conservative** (OpenShift-like)

**Cas d'usage** : Environnements critiques, workloads sensibles

**Caract√©ristiques** :
- Inspir√© de Red Hat OpenShift
- R√©servations major√©es (+30-50% vs GKE)
- Privil√©gie la stabilit√© sur la capacit√©

**Exemple** :
```bash
sudo ./kubelet_auto_config.sh --profile conservative
```

**R√©sultat typique (16 vCPU / 64 GiB)** :
- system-reserved : `660m CPU, 2355Mi RAM`
- kube-reserved : `740m CPU, 4301Mi RAM`
- Allocatable : `14600m CPU, 57.52 GiB RAM`

---

### 4. **Minimal**

**Cas d'usage** : Environnements dev/test, maximiser allocatable

**Caract√©ristiques** :
- R√©servations minimales
- ‚ö†Ô∏è **Attention** : Monitoring requis, risque instabilit√©

**Exemple** :
```bash
sudo ./kubelet_auto_config.sh --profile minimal --dry-run
```

---

## üñ•Ô∏è D√©tection automatique Control-Plane vs Worker

### Pourquoi cette distinction ?

Le script d√©tecte automatiquement le type de n≈ìud et adapte la configuration `enforceNodeAllocatable` :

| Type | enforceNodeAllocatable | Raison |
|------|------------------------|--------|
| **Control-plane** | `["pods", "system-reserved"]` | Les static pods critiques (kube-apiserver, etcd, etc.) doivent d√©marrer **avant** le kubelet. Si `kube-reserved` est enforced, ces pods ne peuvent pas d√©marrer ‚Üí cluster cass√©. |
| **Worker** | `["pods", "system-reserved", "kube-reserved"]` | Enforcement complet recommand√© pour maximiser la stabilit√©. |

### D√©tection automatique (par d√©faut)

Le script d√©tecte automatiquement le type en v√©rifiant la pr√©sence de static pods dans `/etc/kubernetes/manifests/` :

```bash
# Ex√©cution normale (d√©tection auto)
sudo ./kubelet_auto_config.sh

# Sortie sur un control-plane :
# [INFO] D√©tection du type de n≈ìud...
# [SUCCESS] N≈ìud d√©tect√©: CONTROL-PLANE (static pods d√©tect√©s dans /etc/kubernetes/manifests)
# [WARNING] Mode control-plane: kube-reserved ne sera PAS enforced (pour pr√©server les static pods critiques)

# Sortie sur un worker :
# [INFO] D√©tection du type de n≈ìud...
# [SUCCESS] N≈ìud d√©tect√©: WORKER (aucun static pod control-plane trouv√©)
# [INFO] Mode worker: kube-reserved sera enforced normalement
```

### Override manuel (si n√©cessaire)

Dans de rares cas, vous pouvez forcer le type manuellement :

```bash
# Forcer mode control-plane
sudo ./kubelet_auto_config.sh --node-type control-plane

# Forcer mode worker
sudo ./kubelet_auto_config.sh --node-type worker

# Mode auto (par d√©faut, peut √™tre omis)
sudo ./kubelet_auto_config.sh --node-type auto
```

### Important : Control-planes avec taints

Si vos control-planes ont des **taints** et n'ex√©cutent jamais de workloads utilisateur, vous pouvez r√©duire les r√©servations :

```bash
# Control-plane d√©di√© (pas de workloads)
sudo ./kubelet_auto_config.sh --profile minimal --node-type control-plane

# Control-plane mixte (avec workloads)
sudo ./kubelet_auto_config.sh --profile gke --node-type control-plane
```

---

## üéõÔ∏è Density-factor : Adapter selon la densit√© de pods

### Concept

Le **density-factor** est un multiplicateur appliqu√© aux r√©servations pour compenser la charge kubelet selon le nombre de pods par n≈ìud.

### Tableau de recommandations

| Pods/n≈ìud | Density-factor | Commande |
|-----------|----------------|----------|
| **0-30** (faible) | `1.0` (baseline) | Par d√©faut |
| **31-50** (standard) | `1.1` (+10%) | `--density-factor 1.1` |
| **51-80** (√©lev√©e) | `1.2` (+20%) | `--density-factor 1.2` |
| **81-110** (tr√®s √©lev√©e) | `1.5` (+50%) | `--density-factor 1.5` ou `--target-pods 110` |
| **>110** (extr√™me) | `2.0` (+100%) | `--density-factor 2.0` + augmenter `maxPods` |

### Calcul automatique

Le script peut **calculer automatiquement** le density-factor :

```bash
# Cluster avec 110 pods/n≈ìud maximum
sudo ./kubelet_auto_config.sh --profile conservative --target-pods 110

# Le script calcule automatiquement : density-factor = 1.5
```

### Exemples concrets

#### Cluster avec 20 pods/n≈ìud (faible densit√©)
```bash
# Pas de facteur n√©cessaire
sudo ./kubelet_auto_config.sh --profile gke
```

#### Cluster avec 80 pods/n≈ìud (haute densit√©)
```bash
# Facteur 1.2 recommand√©
sudo ./kubelet_auto_config.sh --profile conservative --density-factor 1.2
```

#### Cluster avec 110 pods/n≈ìud (limite maximale)
```bash
# Calcul automatique du facteur
sudo ./kubelet_auto_config.sh --profile conservative --target-pods 110 --backup

# Ou manuellement
sudo ./kubelet_auto_config.sh --profile conservative --density-factor 1.5 --backup
```

---

## üìñ Exemples d'utilisation

### Exemple 1 : Premier test (dry-run)

```bash
# Voir la configuration qui serait appliqu√©e, sans toucher au syst√®me
sudo ./kubelet_auto_config.sh --dry-run

# Sortie :
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
#   CONFIGURATION KUBELET - R√âSERVATIONS CALCUL√âES
# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# 
# Configuration n≈ìud:
#   vCPU:              16
#   RAM:               64 GiB
#   Profil:            gke
#   Density-factor:    1.0
# [...]
```

### Exemple 2 : Configuration standard production

```bash
# N≈ìud g√©n√©raliste, 30-50 pods maximum
sudo ./kubelet_auto_config.sh --profile gke --backup

# V√©rifier les logs kubelet
sudo journalctl -u kubelet -f
```

### Exemple 3 : Cluster haute densit√© (110 pods/n≈ìud)

```bash
# √âtape 1 : Dry-run pour v√©rifier
sudo ./kubelet_auto_config.sh \
  --profile conservative \
  --target-pods 110 \
  --dry-run

# √âtape 2 : Application avec backup
sudo ./kubelet_auto_config.sh \
  --profile conservative \
  --target-pods 110 \
  --backup

# √âtape 3 : Validation
kubectl describe node $(hostname) | grep -A 10 Allocatable
```

### Exemple 4 : Configuration personnalis√©e

```bash
# Profil conservative avec facteur custom
sudo ./kubelet_auto_config.sh \
  --profile conservative \
  --density-factor 1.3 \
  --backup
```

### Exemple 5 : Environnement dev/test (minimal)

```bash
# Maximiser la capacit√© allocatable (avec pr√©caution)
sudo ./kubelet_auto_config.sh \
  --profile minimal \
  --dry-run  # Toujours tester d'abord !
```

---

## üåê D√©ploiement sur un cluster

### Architecture cible

**Exemple** : Cluster de 220 n≈ìuds avec 110 pods/n≈ìud
- **Total** : 24,200 pods dans le cluster
- **Profil** : Conservative + density-factor 1.5

### Strat√©gie de d√©ploiement progressive

```
Phase 1 : 1 n≈ìud pilote     ‚Üí Validation 24-48h
Phase 2 : 10% (22 n≈ìuds)    ‚Üí Validation 7 jours
Phase 3 : 50% (110 n≈ìuds)   ‚Üí Validation 7 jours
Phase 4 : 100% (220 n≈ìuds)  ‚Üí Rollout complet
```

---

### M√©thode 1 : D√©ploiement manuel (petit cluster)

```bash
#!/bin/bash
# deploy-manual.sh

NODES="node1 node2 node3 node4 node5"  # Liste de vos n≈ìuds
PROFILE="conservative"
TARGET_PODS="110"

for node in $NODES; do
    echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
    echo "Configuration du n≈ìud : $node"
    echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
    
    # Copier le script
    scp kubelet_auto_config.sh root@$node:/tmp/
    
    # Ex√©cuter
    ssh root@$node "chmod +x /tmp/kubelet_auto_config.sh && \
                    /tmp/kubelet_auto_config.sh \
                    --profile $PROFILE \
                    --target-pods $TARGET_PODS \
                    --backup"
    
    # V√©rifier le status
    ssh root@$node "systemctl is-active kubelet"
    
    echo ""
    echo "‚úì N≈ìud $node configur√©"
    echo ""
    sleep 5
done

echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
echo "D√©ploiement termin√© sur tous les n≈ìuds"
echo "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ"
```

**Ex√©cution** :
```bash
chmod +x deploy-manual.sh
./deploy-manual.sh
```

---

### M√©thode 2 : D√©ploiement via Ansible (recommand√©)

**Fichier** : `deploy-kubelet-config.yml`

```yaml
---
- name: Configuration des r√©servations kubelet sur tous les n≈ìuds
  hosts: k8s_workers
  become: yes
  vars:
    profile: "conservative"
    target_pods: 110
    backup_enabled: true
  
  tasks:
    - name: V√©rifier les d√©pendances
      package:
        name:
          - bc
          - jq
          - systemd
        state: present
    
    - name: Copier le script de configuration
      copy:
        src: kubelet_auto_config.sh
        dest: /usr/local/bin/kubelet_auto_config.sh
        mode: '0755'
        owner: root
        group: root
    
    - name: Ex√©cuter la configuration (dry-run)
      command: >
        /usr/local/bin/kubelet_auto_config.sh
        --profile {{ profile }}
        --target-pods {{ target_pods }}
        --dry-run
      register: dryrun_output
      changed_when: false
    
    - name: Afficher le r√©sultat du dry-run
      debug:
        var: dryrun_output.stdout_lines
    
    - name: Pause pour validation
      pause:
        prompt: "V√©rifiez les r√©sultats dry-run. Continuer ? (Ctrl+C pour annuler)"
      when: ansible_check_mode == false
    
    - name: Appliquer la configuration kubelet
      command: >
        /usr/local/bin/kubelet_auto_config.sh
        --profile {{ profile }}
        --target-pods {{ target_pods }}
        {% if backup_enabled %}--backup{% endif %}
      register: apply_output
    
    - name: Afficher le r√©sultat de l'application
      debug:
        var: apply_output.stdout_lines
    
    - name: V√©rifier le status kubelet
      systemd:
        name: kubelet
        state: started
        enabled: yes
      register: kubelet_status
    
    - name: Attendre la stabilisation
      wait_for:
        timeout: 30
      delegate_to: localhost
    
    - name: V√©rifier que le n≈ìud est Ready
      shell: kubectl get node {{ inventory_hostname }} -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}'
      delegate_to: localhost
      register: node_ready
      until: node_ready.stdout == "True"
      retries: 6
      delay: 10
    
    - name: Afficher l'allocatable du n≈ìud
      shell: kubectl describe node {{ inventory_hostname }} | grep -A 10 "Allocatable:"
      delegate_to: localhost
      register: allocatable
    
    - debug:
        var: allocatable.stdout_lines

- name: Rapport final
  hosts: localhost
  gather_facts: no
  tasks:
    - name: R√©capitulatif des n≈ìuds configur√©s
      debug:
        msg: "Configuration appliqu√©e sur {{ groups['k8s_workers'] | length }} n≈ìuds"
```

**Inventory Ansible** : `inventory.ini`

```ini
[k8s_workers]
node1.example.com
node2.example.com
node3.example.com
# ... (tous vos n≈ìuds)

[k8s_workers:vars]
ansible_user=root
ansible_ssh_private_key_file=~/.ssh/id_rsa
```

**Ex√©cution** :

```bash
# Dry-run sur tous les n≈ìuds
ansible-playbook -i inventory.ini deploy-kubelet-config.yml --check

# Application r√©elle
ansible-playbook -i inventory.ini deploy-kubelet-config.yml

# Application sur un groupe sp√©cifique (phase progressive)
ansible-playbook -i inventory.ini deploy-kubelet-config.yml --limit "node[1:22]"
```

---

### M√©thode 3 : D√©ploiement via DaemonSet (avanc√©)

‚ö†Ô∏è **Attention** : Cette m√©thode n√©cessite des privil√®ges √©lev√©s (hostPath, privileged)

**Fichier** : `kubelet-config-daemonset.yaml`

```yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: kubelet-config-updater
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: kubelet-config-updater
  template:
    metadata:
      labels:
        app: kubelet-config-updater
    spec:
      hostNetwork: true
      hostPID: true
      priorityClassName: system-node-critical
      tolerations:
      - effect: NoSchedule
        operator: Exists
      containers:
      - name: updater
        image: ubuntu:22.04
        command:
        - /bin/bash
        - -c
        - |
          # Installation des d√©pendances
          apt update && apt install -y bc jq systemd
          
          # Copier le script depuis ConfigMap
          cp /scripts/kubelet_auto_config.sh /tmp/
          chmod +x /tmp/kubelet_auto_config.sh
          
          # Ex√©cuter la configuration
          chroot /host /tmp/kubelet_auto_config.sh \
            --profile conservative \
            --target-pods 110 \
            --backup
          
          # Marquer comme termin√©
          echo "Configuration termin√©e sur $(hostname)"
          sleep infinity
        securityContext:
          privileged: true
        volumeMounts:
        - name: host-root
          mountPath: /host
        - name: scripts
          mountPath: /scripts
      volumes:
      - name: host-root
        hostPath:
          path: /
      - name: scripts
        configMap:
          name: kubelet-config-script
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: kubelet-config-script
  namespace: kube-system
data:
  kubelet_auto_config.sh: |
    # Coller ici le contenu du script bash
```

**D√©ploiement** :
```bash
kubectl apply -f kubelet-config-daemonset.yaml

# Suivre les logs
kubectl logs -n kube-system -l app=kubelet-config-updater -f

# Supprimer apr√®s d√©ploiement
kubectl delete daemonset -n kube-system kubelet-config-updater
```

---

## ‚úÖ Validation post-d√©ploiement

### 1. V√©rifier l'allocatable sur tous les n≈ìuds

```bash
kubectl get nodes -o custom-columns=\
NAME:.metadata.name,\
CPU-CAP:.status.capacity.cpu,\
CPU-ALLOC:.status.allocatable.cpu,\
MEM-CAP:.status.capacity.memory,\
MEM-ALLOC:.status.allocatable.memory
```

**Sortie attendue** :
```
NAME      CPU-CAP   CPU-ALLOC   MEM-CAP      MEM-ALLOC
node1     16        15480m      67108864Ki   63572992Ki
node2     16        15480m      67108864Ki   63572992Ki
node3     16        15480m      67108864Ki   63572992Ki
```

### 2. V√©rifier qu'aucun n≈ìud n'est NotReady

```bash
kubectl get nodes

# Tous les n≈ìuds doivent √™tre Ready
# Si un n≈ìud est NotReady, v√©rifier les logs :
kubectl describe node <node-name>
```

### 3. V√©rifier les cgroups sur un n≈ìud

```bash
# Se connecter √† un n≈ìud
ssh node1

# V√©rifier la hi√©rarchie cgroups
systemd-cgls | grep -E "(system.slice|kubepods.slice|kubelet.slice)"

# Sortie attendue :
# ‚îú‚îÄsystem.slice
# ‚îÇ ‚îú‚îÄcontainerd.service
# ‚îÇ ‚îî‚îÄ...
# ‚îú‚îÄkubelet.slice
# ‚îÇ ‚îî‚îÄkubelet.service
# ‚îî‚îÄkubepods.slice
#   ‚îú‚îÄkubepods-burstable.slice
#   ‚îî‚îÄkubepods-besteffort.slice
```

### 4. V√©rifier les m√©triques kubelet

```bash
# Sur un n≈ìud
curl -s http://localhost:10255/metrics | grep -E "(kubelet_runtime_operations|kubelet_pleg)"

# M√©triques cl√©s :
# - kubelet_pleg_relist_duration_seconds : doit √™tre < 5s
# - kubelet_runtime_operations_duration_seconds : doit √™tre < 2s
```

### 5. V√©rifier les √©victions

```bash
# Aucune √©viction due √† pression m√©moire ne devrait appara√Ætre
kubectl get events --all-namespaces --field-selector reason=Evicted

# Si des √©victions apparaissent, augmenter les r√©servations
```

### 6. Test de charge (optionnel)

```bash
# D√©ployer un workload de test
kubectl create deployment stress-test --image=polinux/stress \
  --replicas=10 -- stress --cpu 1 --vm 1 --vm-bytes 512M --timeout 300s

# Observer la stabilit√© des n≈ìuds
watch -n 2 "kubectl top nodes"

# Nettoyer
kubectl delete deployment stress-test
```

---

## üîÑ Rollback

### En cas de probl√®me

Le script v2.0.3+ conserve automatiquement **plusieurs niveaux de backups** pour faciliter les rollbacks.

#### 1. Restaurer depuis les backups rotatifs (automatiques)

```bash
# Le script conserve automatiquement les 4 derni√®res configurations r√©ussies
# Format : /var/lib/kubelet/config.yaml.last-success.{0,1,2,3}
# .0 = plus r√©cent, .3 = plus ancien

# Lister les backups rotatifs disponibles
ls -lht /var/lib/kubelet/config.yaml.last-success.*

# Revenir √† la derni√®re configuration (1 changement en arri√®re)
sudo cp /var/lib/kubelet/config.yaml.last-success.0 /var/lib/kubelet/config.yaml
sudo systemctl restart kubelet

# Revenir 2 changements en arri√®re
sudo cp /var/lib/kubelet/config.yaml.last-success.1 /var/lib/kubelet/config.yaml
sudo systemctl restart kubelet

# Revenir 3 changements en arri√®re
sudo cp /var/lib/kubelet/config.yaml.last-success.2 /var/lib/kubelet/config.yaml
sudo systemctl restart kubelet

# Revenir 4 changements en arri√®re (le plus ancien)
sudo cp /var/lib/kubelet/config.yaml.last-success.3 /var/lib/kubelet/config.yaml
sudo systemctl restart kubelet
```

#### 2. Restaurer depuis les backups permanents (--backup)

```bash
# Si vous avez utilis√© --backup, des backups permanents timestamp√©s sont conserv√©s
# Format : /var/lib/kubelet/config.yaml.backup.YYYYMMDD_HHMMSS

# Lister les backups permanents
ls -lh /var/lib/kubelet/config.yaml.backup.*

# Restaurer un backup permanent sp√©cifique
sudo cp /var/lib/kubelet/config.yaml.backup.20251021_101234 /var/lib/kubelet/config.yaml
sudo systemctl restart kubelet

# Ou restaurer le dernier backup permanent
LATEST_BACKUP=$(ls -t /var/lib/kubelet/config.yaml.backup.* 2>/dev/null | head -1)
sudo cp "$LATEST_BACKUP" /var/lib/kubelet/config.yaml
sudo systemctl restart kubelet
```

#### 3. Script de rollback automatique

```bash
#!/bin/bash
# rollback-kubelet-config.sh

echo "=== Rollback Configuration Kubelet ==="
echo ""

# Essayer d'abord les backups rotatifs
ROTATIF=$(ls -t /var/lib/kubelet/config.yaml.last-success.* 2>/dev/null | head -1)
if [[ -n "$ROTATIF" ]]; then
    echo "Backup rotatif trouv√© : $ROTATIF"
    sudo cp "$ROTATIF" /var/lib/kubelet/config.yaml
    sudo systemctl restart kubelet
    echo "‚úì Rollback termin√© depuis backup rotatif"
    sudo systemctl status kubelet
    exit 0
fi

# Sinon essayer les backups permanents
PERMANENT=$(ls -t /var/lib/kubelet/config.yaml.backup.* 2>/dev/null | head -1)
if [[ -n "$PERMANENT" ]]; then
    echo "Backup permanent trouv√© : $PERMANENT"
    sudo cp "$PERMANENT" /var/lib/kubelet/config.yaml
    sudo systemctl restart kubelet
    echo "‚úì Rollback termin√© depuis backup permanent"
    sudo systemctl status kubelet
    exit 0
fi

echo "‚úó Aucun backup trouv√©"
exit 1
```

#### 4. Configuration manuelle d'urgence

Si le kubelet ne d√©marre plus :

```bash
# √âditer manuellement la config
sudo vi /var/lib/kubelet/config.yaml

# Supprimer ou ajuster les sections systemReserved et kubeReserved
# Exemple minimal qui fonctionne toujours :
# systemReserved:
#   cpu: "100m"
#   memory: "512Mi"
# kubeReserved:
#   cpu: "100m"
#   memory: "512Mi"

# Red√©marrer
sudo systemctl restart kubelet
sudo journalctl -u kubelet -f
```

---

## ‚ùì FAQ

### Q1 : Le script modifie-t-il d'autres param√®tres kubelet ?

**R** : Non, le script pr√©serve **intelligemment** vos configurations existantes (depuis v2.0.5).

**Comportement :**
- ‚úÖ **Si `/var/lib/kubelet/config.yaml` existe** : Le script **fusionne** avec la configuration existante
  - Modifie uniquement : `systemReserved`, `kubeReserved`, `enforceNodeAllocatable`, cgroups, seuils d'√©viction
  - **Pr√©serve tous les autres param√®tres** : `maxPods`, `imageGCHighThresholdPercent`, `rotateCertificates`, etc.
  - Vos tweaks personnalis√©s sont **conserv√©s** !

- ‚úÖ **Si aucune configuration n'existe** : Le script g√©n√®re une configuration compl√®te avec les valeurs par d√©faut Kubernetes

**Exemple :**
```yaml
# Configuration existante avec tweaks
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
maxPods: 150                          # ‚Üê Tweak personnalis√©
imageGCHighThresholdPercent: 90       # ‚Üê Tweak personnalis√©
systemReserved:
  cpu: "100m"                         # ‚Üê Sera mis √† jour par le script
  memory: "512Mi"                     # ‚Üê Sera mis √† jour par le script

# Apr√®s ex√©cution du script
# maxPods et imageGCHighThresholdPercent restent inchang√©s
# Seuls systemReserved et kubeReserved sont mis √† jour
```

### Q2 : Puis-je ex√©cuter le script plusieurs fois ?

**R** : Oui, le script est **idempotent**. Vous pouvez le relancer sans risque.

**Gestion automatique des backups** (depuis v2.0.3) :
- ‚úÖ **4 backups rotatifs automatiques** : Le script conserve automatiquement les 4 derni√®res configurations r√©ussies (`.last-success.{0,1,2,3}`)
- ‚úÖ **Sans `--backup`** : Rotation automatique, `.0` = plus r√©cent, `.3` = plus ancien
- ‚úÖ **Avec `--backup`** : Cr√©e un backup permanent timestamp√© (conserv√© 90 jours) + rotation automatique

**Exemple** :
```bash
# Premi√®re ex√©cution
sudo ./kubelet_auto_config.sh --profile gke
# Cr√©e : config.yaml.last-success.0

# Deuxi√®me ex√©cution
sudo ./kubelet_auto_config.sh --profile conservative
# Rotation : .0 ‚Üí .1
# Cr√©e : config.yaml.last-success.0 (nouveau)

# Rollback vers la config pr√©c√©dente
sudo cp /var/lib/kubelet/config.yaml.last-success.1 /var/lib/kubelet/config.yaml
sudo systemctl restart kubelet
```

### Q3 : Que se passe-t-il si mes pods d√©passent l'allocatable apr√®s modification ?

**R** : Kubernetes **n'√©vincera PAS** les pods d√©j√† running. Seuls les nouveaux pods seront soumis aux nouvelles limites. Pour forcer un r√©ajustement :

```bash
# Drainer le n≈ìud (optionnel)
kubectl drain <node-name> --ignore-daemonsets --delete-emptydir-data

# Appliquer la config
sudo ./kubelet_auto_config.sh --profile conservative --target-pods 110 --backup

# Rendre le n≈ìud schedulable
kubectl uncordon <node-name>
```

### Q4 : Comment choisir entre GKE et Conservative ?

| Crit√®re | GKE | Conservative |
|---------|-----|--------------|
| **Environnement** | Prod g√©n√©raliste | Critique (finance, sant√©) |
| **Densit√©** | < 80 pods/n≈ìud | > 80 pods/n≈ìud ou haute criticit√© |
| **Allocatable** | Maximis√© | R√©duit de ~15% |
| **Stabilit√©** | Excellente | Maximale |
| **Recommandation** | ‚úÖ D√©faut | Workloads sensibles |

### Q5 : Le script fonctionne-t-il avec cgroups v1 ?

**R** : Oui, le script est compatible cgroups v1 et v2. Il d√©tecte automatiquement la version via `systemd`.

### Q6 : Puis-je personnaliser les valeurs calcul√©es ?

**R** : Le script applique des formules √©prouv√©es. Pour des ajustements fins :

1. Utiliser `--dry-run` pour voir les valeurs
2. Modifier manuellement `/var/lib/kubelet/config.yaml` apr√®s ex√©cution
3. Ou √©diter le script (section `calculate_XXX()`)

### Q7 : Comment surveiller l'impact des r√©servations ?

**R** : M√©triques Prometheus √† surveiller :

```promql
# CPU throttling kubelet (doit √™tre < 5%)
rate(container_cpu_cfs_throttled_seconds_total{container="kubelet"}[5m])

# M√©moire disponible n≈ìud (doit √™tre > 1GiB)
node_memory_MemAvailable_bytes / 1024 / 1024 / 1024

# PLEG latency (doit √™tre < 5s)
kubelet_pleg_relist_duration_seconds{quantile="0.99"}
```

---

## üêõ Troubleshooting

### Probl√®me 0 : Le script affiche `!/bin/bash` au lieu du message d'aide

**Sympt√¥mes** :
```bash
./kubelet_auto_config.sh --help
# !/bin/bash
# ################################################################################
# Script de configuration automatique...
# (Le shebang #! est affich√© sans le #)
```

**Cause** : BOM UTF-8 (Byte Order Mark) invisible au d√©but du fichier

**D√©tection** :
```bash
# V√©rifier les 3 premiers octets
hexdump -C kubelet_auto_config.sh | head -1
# Si vous voyez "ef bb bf" ‚Üí BOM d√©tect√©

# Ou avec file
file kubelet_auto_config.sh
# Si vous voyez "UTF-8 Unicode (with BOM)" ‚Üí BOM d√©tect√©
```

**Solution automatique** :
```bash
# Utiliser le script de diagnostic fourni
bash debug_bom.sh

# Ou manuellement :
# 1. Backup
cp kubelet_auto_config.sh kubelet_auto_config.sh.backup

# 2. Supprimer les 3 premiers octets (BOM)
tail -c +4 kubelet_auto_config.sh > kubelet_auto_config.sh.tmp
mv kubelet_auto_config.sh.tmp kubelet_auto_config.sh
chmod +x kubelet_auto_config.sh

# 3. V√©rifier
./kubelet_auto_config.sh --help  # Doit afficher l'aide correctement
```

**Pr√©vention** :
- Le hook pre-commit Git d√©tecte automatiquement les BOM
- √âviter d'√©diter le script avec des √©diteurs Windows (Notepad)
- Utiliser `vim`, `nano`, ou VSCode avec encoding UTF-8 sans BOM

---

### Probl√®me 1 : Kubelet ne d√©marre pas apr√®s application

**Sympt√¥mes** :
```bash
sudo systemctl status kubelet
# ‚óè kubelet.service - kubelet: The Kubernetes Node Agent
#    Active: failed (Result: exit-code)
```

**Solution** :
```bash
# V√©rifier les logs
sudo journalctl -u kubelet -n 100 --no-pager

# Erreurs fr√©quentes :
# 1. "failed to parse kubelet config file"
#    ‚Üí Syntaxe YAML invalide dans /var/lib/kubelet/config.yaml
#    ‚Üí Restaurer le backup

# 2. "failed to create cgroup"
#    ‚Üí V√©rifier que systemd est bien le cgroup driver
#    ‚Üí V√©rifier : cat /var/lib/kubelet/config.yaml | grep cgroupDriver

# 3. "reservations exceed node capacity"
#    ‚Üí Les r√©servations sont trop √©lev√©es
#    ‚Üí Utiliser --profile minimal ou r√©duire --density-factor
```

### Probl√®me 2 : Allocatable trop faible, pas assez de place pour les pods

**Sympt√¥mes** :
```bash
kubectl describe node <node>
# Allocatable:
#   cpu: 100m  # Presque rien !
#   memory: 1Gi
```

**Cause** : R√©servations trop √©lev√©es (profil conservative + density-factor trop grand)

**Solution** :
```bash
# 1. V√©rifier les r√©servations actuelles
sudo cat /var/lib/kubelet/config.yaml | grep -A 3 "Reserved:"

# 2. Reconfigurer avec un profil moins conservateur
sudo ./kubelet_auto_config.sh --profile gke --backup

# 3. Ou r√©duire le density-factor
sudo ./kubelet_auto_config.sh --profile conservative --density-factor 1.2 --backup
```

### Probl√®me 3 : N≈ìud devient NotReady apr√®s configuration

**Sympt√¥mes** :
```bash
kubectl get nodes
# NAME    STATUS     ROLES    AGE   VERSION
# node1   NotReady   <none>   10d   v1.32.0
```

**Diagnostic** :
```bash
# 1. V√©rifier le kubelet
ssh node1 "sudo systemctl status kubelet"

# 2. V√©rifier les conditions du n≈ìud
kubectl describe node node1 | grep -A 20 "Conditions:"

# Causes fr√©quentes :
# - MemoryPressure: True    ‚Üí system-reserved m√©moire trop faible
# - DiskPressure: True      ‚Üí ephemeral-storage mal configur√©
# - NetworkUnavailable      ‚Üí Probl√®me CNI (non li√© au script)
```

**Solution** :
```bash
# Augmenter les r√©servations
ssh node1 "sudo /usr/local/bin/kubelet_auto_config.sh \
  --profile conservative \
  --density-factor 1.5 \
  --backup"
```

### Probl√®me 4 : √âvictions fr√©quentes apr√®s d√©ploiement

**Sympt√¥mes** :
```bash
kubectl get events --field-selector reason=Evicted
# REASON    MESSAGE
# Evicted   The node was low on resource: memory
```

**Diagnostic** :
```bash
# V√©rifier la pression m√©moire sur les n≈ìuds affect√©s
ssh node1 "cat /sys/fs/cgroup/kubepods.slice/memory.pressure"

# V√©rifier la m√©moire disponible
ssh node1 "free -h"
```

**Solution** :
```bash
# Augmenter system-reserved et kube-reserved
sudo ./kubelet_auto_config.sh \
  --profile conservative \
  --density-factor 1.5 \
  --backup

# OU ajuster manuellement les seuils d'√©viction
sudo vi /var/lib/kubelet/config.yaml
# Modifier :
# evictionHard:
#   memory.available: "1Gi"  # Au lieu de 500Mi
```

### Probl√®me 5 : Script √©choue avec "command not found"

**Sympt√¥mes** :
```bash
./kubelet_auto_config.sh
# line 42: bc: command not found
```

**Solution** :
```bash
# Installer les d√©pendances manquantes
sudo apt update && sudo apt install -y bc jq systemd

# V√©rifier
which bc jq systemctl
```

### Probl√®me 6 : Permission denied lors de l'ex√©cution

**Sympt√¥mes** :
```bash
./kubelet_auto_config.sh
# bash: ./kubelet_auto_config.sh: Permission denied
```

**Solution** :
```bash
# Rendre le script ex√©cutable
chmod +x kubelet_auto_config.sh

# Ex√©cuter avec sudo
sudo ./kubelet_auto_config.sh
```

### Probl√®me 7 : Les cgroups ne sont pas cr√©√©s

**Sympt√¥mes** :
```bash
systemd-cgls | grep kubelet.slice
# (aucun r√©sultat)
```

**Diagnostic** :
```bash
# V√©rifier la configuration kubelet
sudo cat /var/lib/kubelet/config.yaml | grep -E "(enforceNodeAllocatable|Cgroup)"

# V√©rifier les logs
sudo journalctl -u kubelet | grep -i cgroup
```

**Solution** :
```bash
# S'assurer que enforceNodeAllocatable contient bien :
# - "pods"
# - "system-reserved"
# - "kube-reserved"

# R√©appliquer la configuration
sudo ./kubelet_auto_config.sh --profile conservative --backup
```

### Probl√®me 8 : Valeurs diff√©rentes entre n≈ìuds du m√™me type

**Sympt√¥mes** :
```bash
# node1 : Allocatable 15480m CPU
# node2 : Allocatable 15200m CPU (m√™me config mat√©rielle)
```

**Cause** : Le script a √©t√© ex√©cut√© avec des param√®tres diff√©rents

**Solution** :
```bash
# Standardiser sur tous les n≈ìuds
ansible all -i inventory.ini -m shell -a \
  "/usr/local/bin/kubelet_auto_config.sh \
  --profile conservative \
  --target-pods 110 \
  --backup"
```

---

## üìä Monitoring et m√©triques

### Dashboards Grafana recommand√©s

#### Dashboard 1 : Vue d'ensemble des r√©servations

**M√©triques Prometheus** :
```promql
# Allocatable CPU par n≈ìud
kube_node_status_allocatable{resource="cpu",unit="core"}

# Allocatable Memory par n≈ìud
kube_node_status_allocatable{resource="memory",unit="byte"} / 1024 / 1024 / 1024

# Capacity vs Allocatable (ratio de r√©servation)
(kube_node_status_capacity{resource="cpu"} - kube_node_status_allocatable{resource="cpu"}) 
/ kube_node_status_capacity{resource="cpu"} * 100
```

#### Dashboard 2 : Sant√© kubelet

```promql
# PLEG latency (doit √™tre < 5s)
histogram_quantile(0.99, 
  rate(kubelet_pleg_relist_duration_seconds_bucket[5m]))

# Throttling CPU kubelet
rate(container_cpu_cfs_throttled_seconds_total{
  container="kubelet"
}[5m]) * 100

# M√©moire RSS kubelet
process_resident_memory_bytes{job="kubelet"} / 1024 / 1024
```

#### Dashboard 3 : √âvictions

```promql
# Nombre d'√©victions par raison
sum by (reason) (kube_pod_status_reason{reason=~"Evicted|OutOf.*"})

# Taux d'√©victions
rate(kube_pod_status_reason{reason="Evicted"}[5m]) * 60
```

### Alertes recommand√©es

**Fichier** : `kubelet-reservations-alerts.yaml`

```yaml
groups:
- name: kubelet-reservations
  interval: 30s
  rules:
  
  # Alerte : Kubelet CPU throttling √©lev√©
  - alert: KubeletHighCPUThrottling
    expr: |
      rate(container_cpu_cfs_throttled_seconds_total{container="kubelet"}[5m]) > 0.1
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Kubelet throttling CPU √©lev√© sur {{ $labels.node }}"
      description: "Le kubelet sur {{ $labels.node }} subit un throttling CPU de {{ $value | humanizePercentage }}. Augmentez kube-reserved CPU."
  
  # Alerte : PLEG latency trop √©lev√©e
  - alert: KubeletPLEGHighLatency
    expr: |
      histogram_quantile(0.99, 
        rate(kubelet_pleg_relist_duration_seconds_bucket[5m])) > 5
    for: 5m
    labels:
      severity: warning
    annotations:
      summary: "PLEG latency √©lev√©e sur {{ $labels.node }}"
      description: "P99 PLEG latency = {{ $value }}s (seuil: 5s). Consid√©rez augmenter kube-reserved ou r√©duire la densit√© de pods."
  
  # Alerte : M√©moire kubelet √©lev√©e
  - alert: KubeletHighMemoryUsage
    expr: |
      process_resident_memory_bytes{job="kubelet"} / 1024 / 1024 / 1024 > 4
    for: 10m
    labels:
      severity: warning
    annotations:
      summary: "Consommation m√©moire kubelet √©lev√©e sur {{ $labels.instance }}"
      description: "Kubelet utilise {{ $value | humanize }}GiB de RAM. Augmentez kube-reserved memory."
  
  # Alerte : √âvictions fr√©quentes
  - alert: FrequentPodEvictions
    expr: |
      rate(kube_pod_status_reason{reason="Evicted"}[15m]) * 60 > 5
    for: 5m
    labels:
      severity: critical
    annotations:
      summary: "√âvictions fr√©quentes d√©tect√©es"
      description: "{{ $value | humanize }} √©victions/min. V√©rifiez les r√©servations system-reserved et kube-reserved."
  
  # Alerte : Allocatable tr√®s faible
  - alert: NodeLowAllocatable
    expr: |
      (kube_node_status_allocatable{resource="cpu"} / 
       kube_node_status_capacity{resource="cpu"}) < 0.8
    for: 30m
    labels:
      severity: warning
    annotations:
      summary: "Allocatable CPU faible sur {{ $labels.node }}"
      description: "Seulement {{ $value | humanizePercentage }} de CPU allocatable. R√©servations potentiellement trop √©lev√©es."
```

---

## üîê S√©curit√© et bonnes pratiques

### 1. Permissions du script

```bash
# Le script doit appartenir √† root et ne pas √™tre modifiable par d'autres
sudo chown root:root kubelet_auto_config.sh
sudo chmod 750 kubelet_auto_config.sh

# V√©rifier
ls -l kubelet_auto_config.sh
# -rwxr-x--- 1 root root 28472 Jan 20 10:30 kubelet_auto_config.sh
```

### 2. Audit trail

```bash
# Toutes les modifications sont loggu√©es dans syslog
sudo grep "configure-kubelet-reservations" /var/log/syslog

# Ou journalctl
sudo journalctl -t configure-kubelet-reservations
```

### 3. Validation avant production

**Checklist** :
- [ ] Test√© en dry-run sur 1 n≈ìud de dev
- [ ] Test√© en r√©el sur 1 n≈ìud de dev pendant 24h
- [ ] V√©rifi√© allocatable, pas d'√©victions
- [ ] Test√© workload r√©el (charge progressive)
- [ ] Valid√© par l'√©quipe infra/ops
- [ ] Documentation mise √† jour
- [ ] Proc√©dure de rollback test√©e

### 4. Versioning du script

```bash
# Ajouter un num√©ro de version dans le script
VERSION="1.0.0"

# Commit dans Git
git add kubelet_auto_config.sh
git commit -m "feat: script configuration kubelet v1.0.0"
git tag v1.0.0
git push origin v1.0.0
```

---

## üìö Ressources suppl√©mentaires

### Documentation officielle Kubernetes

- [Reserve Compute Resources](https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/)
- [Node Allocatable Resources](https://kubernetes.io/docs/tasks/administer-cluster/reserve-compute-resources/#node-allocatable)
- [Kubelet Configuration Reference](https://kubernetes.io/docs/reference/config-api/kubelet-config.v1beta1/)

### Documentation cloud providers

- [GKE Node Allocatable](https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-architecture#node_allocatable_resources)
- [EKS Allocatable Capacity](https://docs.aws.amazon.com/eks/latest/userguide/allocatable-capacity.html)
- [AKS Resource Reservations](https://learn.microsoft.com/en-us/azure/aks/concepts-clusters-workloads#resource-reservations)

### Benchmarks et √©tudes

- [Kubernetes SIG Scalability Thresholds](https://github.com/kubernetes/community/blob/master/sig-scalability/configs-and-limits/thresholds.md)
- [CNCF Cloud Native Landscape](https://landscape.cncf.io/)

---

## ü§ù Contribution

### Signaler un bug

Ouvrez une issue sur GitHub avec :
- Version du script (voir `--help`)
- Version Kubernetes (`kubectl version`)
- OS et version (`cat /etc/os-release`)
- Logs complets (`journalctl -u kubelet`)

### Proposer une am√©lioration

1. Fork le repository
2. Cr√©ez une branche (`git checkout -b feature/nouvelle-fonctionnalite`)
3. Committez (`git commit -am 'feat: ajout fonctionnalit√© X'`)
4. Push (`git push origin feature/nouvelle-fonctionnalite`)
5. Ouvrez une Pull Request

---


## üìù Changelog et Notes de Version

Pour l'historique complet des versions, consultez les fichiers de changelog d√©di√©s :

- **[CHANGELOG_v2.0.11.md](CHANGELOG_v2.0.11.md)** - Version actuelle (d√©tection auto control-plane/worker)
- **[CHANGELOG_v2.0.10.md](CHANGELOG_v2.0.10.md)** - Correctifs tests critiques
- **[CHANGELOG_v2.0.9.md](CHANGELOG_v2.0.9.md)** - Am√©lioration UX suite de tests
- **[CHANGELOG_v2.0.8.md](CHANGELOG_v2.0.8.md)** - Correctifs critiques ARM64
- Versions pr√©c√©dentes : voir le dossier `changelogs/` (si cr√©√©)

### Version Actuelle : v2.0.11

**Nouveaut√©s :**
- ‚úÖ D√©tection automatique du type de n≈ìud (control-plane vs worker)
- ‚úÖ Adaptation intelligente de `enforceNodeAllocatable` selon le type
- ‚úÖ Option `--node-type` pour override manuel
- ‚úÖ Pr√©vention des crashes de kube-apiserver sur control-planes
- ‚úÖ R√©trocompatible : comportement par d√©faut optimal pour tous les n≈ìuds

**H√©rit√© de v2.0.10 :**
- ‚úÖ Support ARM64 (arithm√©tique d√©cimale)
- ‚úÖ Lock file robuste
- ‚úÖ Formatage YAML propre
- ‚úÖ Suite de tests unitaires (25 tests)
- ‚úÖ Tests compatibles `set -euo pipefail`

Voir [CHANGELOG_v2.0.11.md](CHANGELOG_v2.0.11.md) pour les d√©tails complets.

---
## üìÑ Licence

MIT License

Copyright (c) 2025

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

---

## üÜò Support

### Communaut√©

- **GitHub Issues** : [https://gitlab.com/omega8280051/reserved-sys-kube/-/issues](https://gitlab.com)

---

## ‚ú® Cr√©dits

**D√©velopp√© par** : un stagiaire nomm√© Claude. Mais avec un Senior derri√®re lui quand m√™me. 

**Bas√© sur** :
- Formules officielles Google (GKE)
- Formules officielles Amazon (EKS)
- Recommandations Red Hat (OpenShift)
- Benchmarks Kubernetes SIG Scalability

**Remerciements** :
- Communaut√© Kubernetes
- CNCF (Cloud Native Computing Foundation)
- Contributeurs open source

---

**Note** : Ce script a √©t√© test√© sur les distributions suivantes :
- ‚úÖ Ubuntu 20.04, 22.04, 24.04

**Versions Kubernetes test√©es** :
- ‚úÖ v1.26.x
- ‚úÖ v1.27.x
- ‚úÖ v1.28.x
- ‚úÖ v1.29.x
- ‚úÖ v1.30.x
- ‚úÖ v1.31.x
- ‚úÖ v1.32.x

---

**Derni√®re mise √† jour** : 21 oct 2025
**Version du script** : 2.0.11
**Mainteneur** : Platform Engineering Team
